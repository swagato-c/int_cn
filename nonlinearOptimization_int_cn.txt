OMODULO ONOTModeOCOLONOCOLON "TeXOCOLONUTFOMINUS8"
OBACKSLASHchapterOPENCURLY非线性优化CLOSECURLY
OBACKSLASHlabelOPENCURLYcptOCOLON6CLOSECURLY
OBACKSLASHbeginOPENCURLYmdframedCLOSECURLY  
	OBACKSLASHtextbfOPENCURLY主要目标CLOSECURLY
	OBACKSLASHbeginOPENCURLYenumerateCLOSECURLYOPENSQUARElabelindentOASSIGN0emOCOMMAleftmarginOASSIGN1ODOT5emCLOSESQUARE
		OBACKSLASHitem 理解最小二乘法的含义和处理方式。
		OBACKSLASHitem 理解高斯牛顿法（GaussOMINUSNewton）、列文伯格—马夸尔特方法（LevenburgOMINUSOBACKSLASHOBACKSLASHMarquadt）等下降策略。
		OBACKSLASHitem 学习Ceres库和g2o库的基本使用方法。
	OBACKSLASHendOPENCURLYenumerateCLOSECURLY
OBACKSLASHendOPENCURLYmdframedCLOSECURLY 

在前面几讲，我们介绍了经典SLAM模型的运动方程和观测方程。现在我们已经知道，方程中的位姿可以由变换矩阵来描述，然后用李代数进行优化。观测方程由相机成像模型给出，其中内参是随相机固定的，而外参则是相机的位姿。于是，我们已经弄清了经典SLAM模型在视觉情况下的具体表达。

然而，由于噪声的存在，运动方程和观测方程的等式必定不是精确成立的。尽管相机可以非常好地符合针孔模型，但遗憾的是，我们得到的数据通常是受各种未知噪声影响的。即使我们有高精度的相机，运动方程和观测方程也只能近似成立。所以，与其假设数据必须符合方程，不如来讨论如何在有噪声的数据中进行准确的状态估计。

解决状态估计问题需要一定程度的最优化背景知识。本节将介绍基本的无约束非线性优化方法，同时介绍优化库g2o和Ceres的使用方式。

OBACKSLASHnewpage
OBACKSLASHincludepdfOPENCURLYresourcesODIVIDEotherODIVIDEch6ODOTpdfCLOSECURLY

OBACKSLASHnewpage 
OBACKSLASHsectionOPENCURLY状态估计问题CLOSECURLY
OBACKSLASHsubsectionOPENCURLY批量状态估计与最大后验估计CLOSECURLY
接着前面几讲的内容，我们回顾一下第2讲讨论的经典SLAM模型。它由一个运动方程和一个观测方程构成，如式OBACKSLASHeqrefOPENCURLYeqOCOLONslamproblemCLOSECURLY所示：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHleftOBACKSLASHOPENCURLY OBACKSLASHbeginOPENCURLYarrayCLOSECURLYOPENCURLYlCLOSECURLY
OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OASSIGN fOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYuCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYwCLOSECURLYOUNDERSCOREkOBACKSLASHOBACKSLASH
OPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLY OASSIGN hOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLY OBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYOCOMMAOPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY  OBACKSLASHrightCLOSEBRACKETOPLUS OBACKSLASHbmOPENCURLYvCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLY
OBACKSLASHendOPENCURLYarrayCLOSECURLY OBACKSLASHrightODOT ODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

通过第4讲的知识，我们了解到这里的ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR乃是相机的位姿，可以用ODOLLAROBACKSLASHmathrmOPENCURLYSECLOSECURLYOPENBRACKET3CLOSEBRACKETODOLLAR来描述。至于观测方程，第5讲已经说明，即针孔相机模型。为了让读者对它们有更深的印象，我们不妨讨论一下其具体参数化形式。首先，位姿变量ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR可以由ODOLLAROBACKSLASHbmOPENCURLYTCLOSECURLYOUNDERSCOREk OBACKSLASHin OBACKSLASHmathrmOPENCURLYSECLOSECURLYOPENBRACKET3CLOSEBRACKET ODOLLAR表达。其次，运动方程与输入的具体形式有关，但在视觉SLAM中没有特殊性（和普通的机器人、车辆的情况一样），我们暂且不谈。观测方程则由针孔模型给定。假设在ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR处对路标ODOLLAROBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjODOLLAR进行了一次观测，对应到图像上的像素位置ODOLLAROBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYODOLLAR，那么，观测方程可以表示成
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
s OBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOASSIGN OBACKSLASHbmOPENCURLYKCLOSECURLY OPENBRACKETOBACKSLASHbmOPENCURLYRCLOSECURLYOUNDERSCOREk OPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYOPLUSOBACKSLASHbmOPENCURLYtCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
其中ODOLLAROBACKSLASHbmOPENCURLYKCLOSECURLYODOLLAR为相机内参，ODOLLARsODOLLAR为像素点的距离，也是ODOLLAROPENBRACKETOBACKSLASHbmOPENCURLYRCLOSECURLYOUNDERSCOREk OPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYOPLUSOBACKSLASHbmOPENCURLYtCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOLLAR的第三个分量。如果使用变换矩阵ODOLLAROBACKSLASHbmOPENCURLYTCLOSECURLYOUNDERSCOREkODOLLAR描述位姿，那么路标点ODOLLAROBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjODOLLAR必须以齐次坐标来描述，计算完成后要转换为非齐次坐标。如果你还不熟悉这个过程，请到上一讲回顾一遍。

现在，考虑数据受噪声影响后会发生什么改变。在运动和观测方程中，我们OBACKSLASHtextbfOPENCURLY通常CLOSECURLY假设两个噪声项ODOLLAROBACKSLASHbmOPENCURLYwCLOSECURLYOUNDERSCOREkOCOMMA OBACKSLASHbmOPENCURLYvCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYODOLLAR满足零均值的高斯分布，像这样：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OPENCURLYOBACKSLASHbmOPENCURLYwCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLY0CLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYRCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYvCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLY0CLOSECURLYOCOMMAOPENCURLYOPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYQCLOSECURLYCLOSECURLYCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
其中ODOLLAROBACKSLASHmathcalOPENCURLYNCLOSECURLYODOLLAR表示高斯分布，ODOLLAROBACKSLASHbmOPENCURLY0CLOSECURLYODOLLAR表示零均值，ODOLLAROBACKSLASHbmOPENCURLYRCLOSECURLYOUNDERSCOREkOCOMMA OBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYODOLLAR为协方差矩阵。在这些噪声的影响下，我们希望通过带噪声的数据ODOLLAROBACKSLASHbmOPENCURLYzCLOSECURLYODOLLAR和ODOLLAROBACKSLASHbmOPENCURLYuCLOSECURLYODOLLAR推断位姿ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR和地图ODOLLAROBACKSLASHbmOPENCURLYyCLOSECURLYODOLLAR（以及它们的概率分布），这构成了一个状态估计问题。

处理这个状态估计问题的方法大致分成两种。由于在SLAM过程中，这些数据是随时间逐渐到来的，所以在直观上，我们应该持有一个当前时刻的估计状态，然后用新的数据来更新它。这种方式称为OBACKSLASHtextbfOPENCURLY增量ODIVIDE渐进CLOSECURLY（incremental）的方法，或者叫OBACKSLASHtextbfOPENCURLY滤波器CLOSECURLY。在历史上很长一段时间内，研究者们使用滤波器，尤其是扩展卡尔曼滤波器（EKF）及其衍生方法求解它。另一种方式，则是把数据“攒”起来一并处理，这种方式称为OBACKSLASHtextbfOPENCURLY批量CLOSECURLY（batch）的方法。例如，我们可以把0到ODOLLARkODOLLAR时刻所有的输入和观测数据都放在一起，问，在这样的输入和观测下，如何估计整个0到ODOLLARkODOLLAR时刻的轨迹与地图？

这两种不同的处理方式引出了很多不同的估计手段。大体来说，增量方法仅关心OBACKSLASHtextbfOPENCURLY当前时刻CLOSECURLY的状态估计ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR，而对之前的状态则不多考虑；相对地，批量方法可以在OBACKSLASHtextbfOPENCURLY更大的范围CLOSECURLY达到最优化，被认为优于传统的滤波器OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYStrasdat2012CLOSECURLYCLOSECURLY，而成为当前视觉SLAM的主流方法。极端情况下，我们可以让机器人或无人机收集所有时刻的数据，再带回计算中心统一处理，这也正是SfM（Structure from Motion）的主流做法。当然，这种极端情况显然是不OBACKSLASHtextbfOPENCURLY实时CLOSECURLY的，不符合SLAM的运用场景。所以在SLAM中，实用的方法通常是一些折衷的手段。比如，我们固定一些历史轨迹，仅对当前时刻附近的一些轨迹进行优化，这是后面要讲到的OBACKSLASHtextbfOPENCURLY滑动窗口估计CLOSECURLY法。

在理论上，批量方法更加容易介绍。同时，理解了批量方法也更容易理解增量的方法。所以本节我们重点介绍以非线性优化为主的批量优化方法，对卡尔曼滤波器以及更深入的知识则留到后端章节再进行讨论。由于讨论的是批量方法，考虑从1到ODOLLARNODOLLAR的所有时刻，并假设有ODOLLARMODOLLAR个路标点。定义所有时刻的机器人位姿和路标点坐标为：
OBACKSLASHOPENSQUARE
OBACKSLASHbmOPENCURLYxCLOSECURLYOASSIGNOBACKSLASHOPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCORE1OCOMMA OBACKSLASHldotsOCOMMA OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREN OBACKSLASHCLOSECURLYOCOMMA OBACKSLASHquad OBACKSLASHbmOPENCURLYyCLOSECURLY OASSIGN OBACKSLASHOPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCORE1OCOMMA OBACKSLASHldotsOCOMMA OBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREM OBACKSLASHCLOSECURLYODOT
OBACKSLASHCLOSESQUARE
同样地，用不带下标的ODOLLAROBACKSLASHbmOPENCURLYuCLOSECURLYODOLLAR表示所有时刻的输入，ODOLLAROBACKSLASHbmOPENCURLYzCLOSECURLYODOLLAR表示所有时刻的观测数据。那么我们说，对机器人状态的估计，从概率学的观点来看，就是已知输入数据ODOLLAROBACKSLASHbmOPENCURLYuCLOSECURLYODOLLAR和观测数据ODOLLAROBACKSLASHbmOPENCURLYzCLOSECURLYODOLLAR的条件下，求状态ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYODOLLAR的条件概率分布：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLY OBBOR OBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYuCLOSECURLYCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
特别地，当我们不知道控制输入，只有一张张的图像时，即只考虑观测方程带来的数据时，相当于估计ODOLLARPOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLY OBBOR OBACKSLASHbmOPENCURLYzCLOSECURLY CLOSEBRACKETODOLLAR的条件概率分布，此问题也称为Structure from Motion（SfM），即如何从许多图像中重建三维空间结构OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYAgarwal2009CLOSECURLYCLOSECURLY。

为了估计状态变量的条件分布，利用贝叶斯法则，有：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POBACKSLASHleftOPENBRACKET OPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYOBBOR OBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYuCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHfracOPENCURLYOPENCURLYPOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBBOROBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETPOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYyCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYPOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBACKSLASHrightCLOSEBRACKETCLOSECURLYCLOSECURLY OBACKSLASHpropto OBACKSLASHunderbraceOPENCURLYPOBACKSLASHleftOPENBRACKET  OPENCURLY OBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBBOR OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLY CLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHtextOPENCURLY似然CLOSECURLYCLOSECURLY OBACKSLASHunderbraceOPENCURLYPOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHtextOPENCURLY先验CLOSECURLYCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
贝叶斯法则左侧称为OBACKSLASHtextbfOPENCURLY后验概率CLOSECURLY，右侧的ODOLLARPOPENBRACKETOBACKSLASHbmOPENCURLYzCLOSECURLYOBBOROBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR称为OBACKSLASHtextbfOPENCURLY似然CLOSECURLY（Likehood），另一部分ODOLLARPOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR称为OBACKSLASHtextbfOPENCURLY先验CLOSECURLY（Prior）。OBACKSLASHtextbfOPENCURLY直接求后验分布是困难的，但是求一个状态最优估计，使得在该状态下后验概率最大化CLOSECURLY（Maximize a Posterior，MAP），则是可行的：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OPENCURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKETOHATOMULTIPLYCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHmathrmOPENCURLYMAPCLOSECURLYCLOSECURLY OASSIGN OBACKSLASHarg OPENCURLYOBACKSLASHmathopOPENCURLYOBACKSLASHrm maxCLOSECURLYOBACKSLASHnolimitsCLOSECURLYOBACKSLASH  P OBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYOBBOROBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHarg OBACKSLASHmax POPENBRACKETOBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBBOROBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKETPOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
请注意贝叶斯法则的分母部分与待估计的状态ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYODOLLAR无关，因而可以忽略。贝叶斯法则告诉我们，求解最大后验概率OBACKSLASHtextbfOPENCURLY等价于最大化似然和先验的乘积CLOSECURLY。进一步，我们当然也可以说，对不起，我不知道机器人位姿或路标大概在什么地方，此时就没有了OBACKSLASHtextbfOPENCURLY先验CLOSECURLY。那么，可以求解OBACKSLASHtextbfOPENCURLY最大似然估计CLOSECURLY（Maximize Likelihood Estimation，MLE）：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OPENCURLY OPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKETOHATOMULTIPLYCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHmathrmOPENCURLYMLECLOSECURLYCLOSECURLY OASSIGN OBACKSLASHarg OBACKSLASHmax POPENBRACKET OBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBBOR OBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

直观讲，似然是指“在现在的位姿下，可能产生怎样的观测数据”。由于我们知道观测数据，所以最大似然估计可以理解成：“OBACKSLASHtextbfOPENCURLY在什么样的状态下，最可能产生现在观测到的数据”CLOSECURLY。这就是最大似然估计的直观意义。

OBACKSLASHsubsectionOPENCURLY最小二乘的引出CLOSECURLY
那么如何求最大似然估计呢？我们说，在高斯分布的假设下，最大似然能够有较简单的形式。回顾观测模型，对于某一次观测：
OBACKSLASHOPENSQUARE
OPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLY OASSIGN hOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLY OBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYOCOMMAOPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY  OBACKSLASHrightCLOSEBRACKETOPLUS OBACKSLASHbmOPENCURLYvCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOCOMMA
OBACKSLASHCLOSESQUARE
由于我们假设了噪声项ODOLLAROPENCURLYOBACKSLASHbmOPENCURLYvCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLY0CLOSECURLYOCOMMAOPENCURLYOPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYQCLOSECURLYCLOSECURLYCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOLLAR，所以观测数据的条件概率为：
OBACKSLASHOPENSQUARE
POPENBRACKET OBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYjOCOMMAkCLOSECURLY OBBOR OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOCOMMA OBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREj CLOSEBRACKET OASSIGN NOBACKSLASHleftOPENBRACKET hOPENBRACKETOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjOCOMMA OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETOCOMMA OBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHCLOSESQUARE
它依然是一个高斯分布。考虑单次观测的最大似然估计，可以使用OBACKSLASHtextbfOPENCURLY最小化负对数CLOSECURLY来求一个高斯分布的最大似然。

我们知道高斯分布在负对数下有较好的数学形式。考虑任意高维高斯分布ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYOBACKSLASHmuCLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYOBACKSLASHSigmaCLOSECURLYCLOSEBRACKETODOLLAR，它的概率密度函数展开形式为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLYOPENCURLYOBACKSLASHsqrt OPENCURLYOPENCURLYOPENCURLYOPENBRACKET2OBACKSLASHpi CLOSEBRACKETCLOSECURLYOHATNCLOSECURLYOBACKSLASHdet OPENBRACKET OBACKSLASHbmOPENCURLYOBACKSLASHSigmaCLOSECURLY CLOSEBRACKETCLOSECURLY CLOSECURLYCLOSECURLYOBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLY OMINUS OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOPENCURLYOBACKSLASHleftOPENBRACKET OPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLY OMINUS OBACKSLASHbmOPENCURLYOBACKSLASHmuCLOSECURLY CLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOPENCURLY OBACKSLASHbmOPENCURLYOBACKSLASHSigmaCLOSECURLY OHATOPENCURLY OMINUS 1CLOSECURLYCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLY OMINUS OBACKSLASHbmOPENCURLYOBACKSLASHmuCLOSECURLY CLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
对其取负对数，则变为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OMINUS OBACKSLASHln OBACKSLASHleftOPENBRACKET OPENCURLYPOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHln OBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOPENCURLYOBACKSLASHleftOPENBRACKET OPENCURLY2OBACKSLASHpi CLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOHATNCLOSECURLYOBACKSLASHdet OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYOBACKSLASHSigmaCLOSECURLY  OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOPENBRACKET OPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLY OMINUS OBACKSLASHbmOPENCURLYOBACKSLASHmuCLOSECURLY CLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOPENCURLYOBACKSLASHbmOPENCURLYOBACKSLASHSigmaCLOSECURLY OHATOPENCURLY OMINUS 1CLOSECURLYCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLY OMINUS OBACKSLASHbmOPENCURLYOBACKSLASHmuCLOSECURLY CLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
因为对数函数是单调递增的，所以对原函数求最大化相当于对负对数求最小化。在最小化上式的ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR时，第一项与ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR无关，可以略去。于是，只要最小化右侧的二次型项，就得到了对状态的最大似然估计。代入SLAM的观测模型，相当于在求：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYalignedCLOSECURLY
OPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSEBRACKETOHATOMULTIPLY OBANDOASSIGN OBACKSLASHarg OBACKSLASHmax OBACKSLASHmathcalOPENCURLYNCLOSECURLYOPENBRACKEThOPENBRACKETOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjOCOMMA OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETOCOMMA OBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSEBRACKET OBACKSLASHOBACKSLASH OBANDOASSIGN  OBACKSLASHarg OBACKSLASHmin OBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOPENCURLYOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLY OBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLY OMINUS hOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLY OBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOHATOPENCURLY OMINUS 1CLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLY OMINUS hOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYalignedCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY

我们发现，该式等价于最小化噪声项（即误差）的一个二次型。这个二次型称为OBACKSLASHtextbfOPENCURLY马哈拉诺比斯距离CLOSECURLY（Mahalanobis distance），又叫OBACKSLASHtextbfOPENCURLY马氏距离CLOSECURLY。它也可以看成是由ODOLLAROBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLYODOLLAR加权之后的欧氏距离（二范数），这里ODOLLAROBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLYODOLLAR也叫做OBACKSLASHtextbfOPENCURLY信息矩阵CLOSECURLY，即高斯分布协方差矩阵之逆。

现在我们考虑批量时刻的数据。通常假设各个时刻的输入和观测是相互独立的，这意味着各个输入之间是独立的，各个观测之间是独立的，并且输入和观测也是独立的。于是我们可以对联合分布进行因式分解：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYuCLOSECURLYOBBOROBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHprodOBACKSLASHlimitsOUNDERSCOREk OPENCURLYPOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYuCLOSECURLYOUNDERSCOREkCLOSECURLYOBBOROPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHprodOBACKSLASHlimitsOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLY OPENCURLYPOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLYOBBOROPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOCOMMA	
OBACKSLASHendOPENCURLYequationCLOSECURLY
这说明我们可以独立地处理各时刻的运动和观测。定义各次输入和观测数据与模型之间的误差：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYarrayCLOSECURLYOPENCURLYlCLOSECURLY
OPENCURLYOBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYCLOSECURLY OASSIGN OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OMINUS fOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYuCLOSECURLYOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHOBACKSLASH
OPENCURLYOBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYzOCOMMAjOCOMMAkCLOSECURLYCLOSECURLY OASSIGN OPENCURLYOBACKSLASHbmOPENCURLYzCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYCLOSECURLY OMINUS hOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLYOCOMMAOPENCURLYOBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETOCOMMA
OBACKSLASHendOPENCURLYarrayCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY
那么，最小化所有时刻估计值与真实读数之间马氏距离，等价于求最大似然估计。负对数允许我们把乘积变成求和：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHlabelOPENCURLYeqOCOLONleastOMINUSsquareCLOSECURLY
OBACKSLASHmin J OPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYyCLOSECURLYCLOSEBRACKET OASSIGN OBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREk OPENCURLYOBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHbmOPENCURLYRCLOSECURLYOUNDERSCOREkOHATOPENCURLY OMINUS 1CLOSECURLYOPENCURLY OBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYCLOSECURLYCLOSECURLY  OPLUS OBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREk OPENCURLYOBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREj OPENCURLYOBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYzOCOMMAkOCOMMAjCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHbmOPENCURLYQCLOSECURLYOUNDERSCOREOPENCURLYkOCOMMAjCLOSECURLYOHATOPENCURLY OMINUS 1CLOSECURLYOPENCURLYOBACKSLASHbmOPENCURLYeCLOSECURLYOUNDERSCOREOPENCURLYzOCOMMAkOCOMMAjCLOSECURLYCLOSECURLYCLOSECURLY CLOSECURLY ODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
这样就得到了一个OBACKSLASHtextbfOPENCURLY最小二乘问题CLOSECURLY（Least Square Problem），它的解等价于状态的最大似然估计。直观上看，由于噪声的存在，当我们把估计的轨迹与地图代入SLAM的运动、观测方程中时，它们并不会完美地成立。这时怎么办呢？我们对状态的估计值进行OBACKSLASHtextbfOPENCURLY微调CLOSECURLY，使得整体的误差下降一些。当然这个下降也有限度，它一般会到达一个OBACKSLASHtextbfOPENCURLY极小值CLOSECURLY。这就是一个典型非线性优化的过程。

仔细观察式OBACKSLASHeqrefOPENCURLYeqOCOLONleastOMINUSsquareCLOSECURLY，我们发现SLAM中的最小二乘问题具有一些特定的结构：

OBACKSLASHbeginOPENCURLYitemizeCLOSECURLY
	OBACKSLASHitem 首先，整个问题的目标函数由许多个误差的（加权的）二次型组成。虽然总体的状态变量维数很高，但每个误差项都是简单的，仅与一两个状态变量有关。例如，运动误差只与ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYkOMINUS1CLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR有关，观测误差只与ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOCOMMA OBACKSLASHbmOPENCURLYyCLOSECURLYOUNDERSCOREjODOLLAR有关。这种关系会让整个问题有一种OBACKSLASHtextbfOPENCURLY稀疏CLOSECURLY的形式，我们将在后端章节中看到。
	
	OBACKSLASHitem 其次，如果使用李代数表示增量，则该问题是OBACKSLASHtextbfOPENCURLY无约束CLOSECURLY的最小二乘问题。但如果用旋转矩阵ODIVIDE变换矩阵描述位姿，则会引入旋转矩阵自身的约束，即需在问题中加入ODOLLAROBACKSLASHmathrmOPENCURLYsODOTtODOTCLOSECURLYOBACKSLASH OBACKSLASHbmOPENCURLYRCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHbmOPENCURLYRCLOSECURLYOASSIGNOBACKSLASHbmOPENCURLYICLOSECURLY OBACKSLASHtextOPENCURLY且CLOSECURLY OBACKSLASHdet OPENBRACKETOBACKSLASHbmOPENCURLYRCLOSECURLYCLOSEBRACKETOASSIGN1ODOLLAR这样令人头大的条件。额外的约束会使优化变得更困难。这体现了李代数的优势。
	
	OBACKSLASHitem 最后，我们使用了二次型度量误差。误差的分布将影响此项在整个问题中的权重。例如，某次的观测非常准确，那么协方差矩阵就会“小”，而信息矩阵就会“大”，所以这个误差项会在整个问题中占有较高的权重。我们之后也会看到它存在一些问题，但是目前先不讨论。
OBACKSLASHendOPENCURLYitemizeCLOSECURLY

现在，我们介绍如何求解这个最小二乘问题，这需要一些OBACKSLASHtextbfOPENCURLY非线性优化的基本知识CLOSECURLY。特别地，我们要针对这样一个通用的无约束非线性最小二乘问题，探讨它是如何求解的。在后续几讲中，我们会大量使用本讲的结果，详细讨论它在SLAM前端、后端中的应用。

OBACKSLASHsubsectionOPENCURLY例子：批量状态估计CLOSECURLY
我发现在这里举一个简单的例子会更好一些。考虑一个非常简单的离散时间系统：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYarrayCLOSECURLYOPENCURLYlllCLOSECURLY
OPENCURLYxOUNDERSCOREkCLOSECURLY OBANDOASSIGN OPENCURLYxOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLY OPLUS OPENCURLYuOUNDERSCOREkCLOSECURLY OPLUS OPENCURLYwOUNDERSCOREkCLOSECURLYOCOMMAOBANDOBACKSLASHqquad wOUNDERSCOREk OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLY0OCOMMAQOUNDERSCOREkCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHOBACKSLASH
OPENCURLYzOUNDERSCOREkCLOSECURLY OBANDOASSIGN OPENCURLYxOUNDERSCOREkCLOSECURLY OPLUS OPENCURLYnOUNDERSCOREkCLOSECURLYOCOMMAOBANDOBACKSLASHqquad OPENCURLYnOUNDERSCOREkCLOSECURLYOBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLY0OCOMMAROUNDERSCOREkCLOSECURLY OBACKSLASHrightCLOSEBRACKET
OBACKSLASHendOPENCURLYarrayCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY
这可以表达一辆沿ODOLLARxODOLLAR轴前进或后退的汽车。第一个公式为运动方程，ODOLLARuOUNDERSCOREkODOLLAR为输入，ODOLLARwOUNDERSCOREkODOLLAR为噪声；第二个公式为观测方程，ODOLLARzOUNDERSCOREkODOLLAR为对汽车位置的测量。取时间ODOLLARkOASSIGN1OCOMMAOBACKSLASHldotsOCOMMA3ODOLLAR，现希望根据已有的ODOLLARvOCOMMAyODOLLAR进行状态估计。设初始状态ODOLLARxOUNDERSCORE0ODOLLAR已知。下面来推导批量（batch）状态的最大似然估计。

首先，令批量状态变量为ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OPENSQUARExOUNDERSCORE0OCOMMAxOUNDERSCORE1OCOMMA xOUNDERSCORE2OCOMMA xOUNDERSCORE3CLOSESQUAREOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR，令批量观测为ODOLLAROBACKSLASHbmOPENCURLYzCLOSECURLY OASSIGN OPENSQUAREzOUNDERSCORE1OCOMMAzOUNDERSCORE2OCOMMAzOUNDERSCORE3CLOSESQUAREOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR，按同样方式定义ODOLLAROBACKSLASHbmOPENCURLYuCLOSECURLYOASSIGNOPENSQUAREuOUNDERSCORE1OCOMMAuOUNDERSCORE2OCOMMAuOUNDERSCORE3CLOSESQUAREOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR。按照先前的推导，我们知道最大似然估计为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYalignedCLOSECURLY
OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHmathrmOPENCURLYmapCLOSECURLYCLOSECURLYOHATOMULTIPLYCLOSECURLY OBANDOASSIGN OBACKSLASHarg OBACKSLASHmax POPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOBBOROBACKSLASHbmOPENCURLYuCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYzCLOSECURLYCLOSEBRACKET OASSIGN OBACKSLASHarg OBACKSLASHmax POPENBRACKETOBACKSLASHbmOPENCURLYuCLOSECURLYOCOMMAOBACKSLASHbmOPENCURLYzCLOSECURLYOBBOROBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETOBACKSLASHOBACKSLASH
 OBANDOASSIGN OBACKSLASHprodOBACKSLASHlimitsOUNDERSCOREOPENCURLYk OASSIGN 1CLOSECURLYOHAT3 OPENCURLYPOPENBRACKETOPENCURLYuOUNDERSCOREkCLOSECURLYOBBOROPENCURLYxOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYxOUNDERSCOREkCLOSECURLYCLOSEBRACKETOBACKSLASHprodOBACKSLASHlimitsOUNDERSCOREOPENCURLYk OASSIGN 1CLOSECURLYOHAT3 OPENCURLYPOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYzOUNDERSCOREkCLOSECURLYOBBOROPENCURLYxOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY CLOSECURLYOCOMMA 
OBACKSLASHendOPENCURLYalignedCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY
对于具体的每一项，比如运动方程，我们知道：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POPENBRACKETOPENCURLYuOUNDERSCOREkCLOSECURLYOBBOROPENCURLYxOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYxOUNDERSCOREkCLOSECURLYCLOSEBRACKET OASSIGN OBACKSLASHmathcalOPENCURLYNCLOSECURLYOPENBRACKETOPENCURLYxOUNDERSCOREkCLOSECURLY OMINUS OPENCURLYxOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLYOCOMMAOPENCURLYQOUNDERSCOREkCLOSECURLYCLOSEBRACKETOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
观测方程也是类似的：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
POBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYzOUNDERSCOREkCLOSECURLYOBBOROPENCURLYxOUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OASSIGN OBACKSLASHmathcalOPENCURLYNCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYxOUNDERSCOREkCLOSECURLYOCOMMAOPENCURLYROUNDERSCOREkCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
根据这些方法，我们就能够实际地解决上面的批量状态估计问题。根据之前的叙述，可以构建误差变量：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OPENCURLYeOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYCLOSECURLY OASSIGN OPENCURLYxOUNDERSCOREkCLOSECURLY OMINUS OPENCURLYxOUNDERSCOREOPENCURLYk OMINUS 1CLOSECURLYCLOSECURLY OMINUS OPENCURLYuOUNDERSCOREkCLOSECURLYOCOMMA OBACKSLASHquad OPENCURLYeOUNDERSCOREOPENCURLYzOCOMMAkCLOSECURLYCLOSECURLY OASSIGN OPENCURLYzOUNDERSCOREkCLOSECURLY OMINUS OPENCURLYxOUNDERSCOREkCLOSECURLYOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
于是最小二乘的目标函数为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHmin OBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREOPENCURLYk OASSIGN 1CLOSECURLYOHAT3 OPENCURLYeOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY QOUNDERSCOREkOHATOPENCURLY OMINUS 1CLOSECURLYOPENCURLYeOUNDERSCOREOPENCURLYuOCOMMAkCLOSECURLYCLOSECURLYCLOSECURLY  OPLUS OBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREOPENCURLYk OASSIGN 1CLOSECURLYOHAT3 OPENCURLYeOUNDERSCOREOPENCURLYzOCOMMAkCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYOPENCURLYROHATOPENCURLY OMINUS 1CLOSECURLYOUNDERSCOREkCLOSECURLYOPENCURLYeOUNDERSCOREOPENCURLYzOCOMMAkCLOSECURLYCLOSECURLYCLOSECURLYODOT 
OBACKSLASHendOPENCURLYequationCLOSECURLY

此外，这个系统是线性系统，我们可以很容易地将它写成向量形式。定义向量ODOLLAROBACKSLASHbmOPENCURLYyCLOSECURLYOASSIGNOPENSQUAREOBACKSLASHbmOPENCURLYuCLOSECURLYOCOMMA OBACKSLASHbmOPENCURLYzCLOSECURLYCLOSESQUAREOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR，那么可以写出矩阵ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR，使得：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbmOPENCURLYyCLOSECURLYOMINUSOBACKSLASHbmOPENCURLYHCLOSECURLYOBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYeCLOSECURLY OBACKSLASHsim OBACKSLASHmathcalOPENCURLYNCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLY0CLOSECURLYOCOMMA OBACKSLASHboldsymbolOPENCURLYOBACKSLASHSigmaCLOSECURLYCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
那么：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbmOPENCURLYHCLOSECURLY OASSIGN OBACKSLASHleftOPENSQUARE OPENCURLYOBACKSLASHbeginOPENCURLYarrayCLOSECURLYOPENCURLYOMULTIPLYOPENCURLY20CLOSECURLYOPENCURLYcCLOSECURLYCLOSECURLY
1OBANDOPENCURLY OMINUS 1CLOSECURLYOBAND0OBAND0OBACKSLASHOBACKSLASH
0OBAND1OBANDOPENCURLY OMINUS 1CLOSECURLYOBAND0OBACKSLASHOBACKSLASH
0OBAND0OBAND1OBANDOPENCURLY OMINUS 1CLOSECURLYOBACKSLASHOBACKSLASH
OBACKSLASHhline
0OBAND1OBAND0OBAND0OBACKSLASHOBACKSLASH
0OBAND0OBAND1OBAND0OBACKSLASHOBACKSLASH
0OBAND0OBAND0OBAND1
OBACKSLASHendOPENCURLYarrayCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSESQUAREOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
且ODOLLAROBACKSLASHboldsymbolOPENCURLYOBACKSLASHSigmaCLOSECURLYOASSIGNOBACKSLASHmathrmOPENCURLYdiagCLOSECURLYOPENBRACKETQOUNDERSCORE1OCOMMA QOUNDERSCORE2OCOMMA QOUNDERSCORE3OCOMMA ROUNDERSCORE1OCOMMA ROUNDERSCORE2OCOMMA ROUNDERSCORE3CLOSEBRACKETODOLLAR。整个问题可以写成：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOMULTIPLYOUNDERSCOREOPENCURLYOBACKSLASHmathrmOPENCURLYmapCLOSECURLYCLOSECURLY OASSIGN OBACKSLASHarg OBACKSLASHmin OBACKSLASHbmOPENCURLYeCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHboldsymbolOPENCURLYOBACKSLASHSigmaCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLY OBACKSLASHbmOPENCURLYeCLOSECURLYOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
之后我们将看到，这个问题有唯一的解：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOMULTIPLYOUNDERSCOREOPENCURLYOBACKSLASHmathrmOPENCURLYmapCLOSECURLYCLOSECURLY OASSIGN OPENBRACKETOBACKSLASHbmOPENCURLYHCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHboldsymbolOPENCURLYOBACKSLASHSigmaCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLY OBACKSLASHbmOPENCURLYHCLOSECURLYCLOSEBRACKETOHATOPENCURLYOMINUS1CLOSECURLY OBACKSLASHbmOPENCURLYHCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHboldsymbolOPENCURLYOBACKSLASHSigmaCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLY OBACKSLASHbmOPENCURLYyCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

OBACKSLASHsectionOPENCURLY非线性最小二乘CLOSECURLY
OBACKSLASHlabelOPENCURLYsecOCOLON6ODOT2CLOSECURLY
先来考虑一个简单的最小二乘问题：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHmathop OPENCURLYOBACKSLASHmin CLOSECURLYOBACKSLASHlimitsOUNDERSCOREOPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY FOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKET OASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2OUNDERSCORE2CLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
其中，自变量ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHin OBACKSLASHmathbbOPENCURLYRCLOSECURLYOHATnODOLLAR，ODOLLARfODOLLAR是任意标量非线性函数ODOLLARfOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETOCOLON OBACKSLASHmathbbOPENCURLYRCLOSECURLYOHATn OBACKSLASHmapsto OBACKSLASHmathbbOPENCURLYRCLOSECURLYODOLLAR。注意这里的系数ODOLLAROBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYODOLLAR是无关紧要的，有些文献上带有这个系数，有些文献则不带，它也不会影响之后的结论。下面讨论如何求解这样一个优化问题。显然，如果ODOLLARfODOLLAR是个数学形式上很简单的函数，那么该问题可以用解析形式来求。令目标函数的导数为零，然后求解ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的最优值，就和求二元函数的极值一样：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHfracOPENCURLY OBACKSLASHmathrmOPENCURLYdCLOSECURLY FCLOSECURLYOPENCURLY OBACKSLASHmathrmOPENCURLYdCLOSECURLY OBACKSLASHbmOPENCURLYxCLOSECURLY CLOSECURLY OASSIGN OBACKSLASHbmOPENCURLY0CLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
解此方程，就得到了导数为零处的极值。它们可能是极大、极小或鞍点处的值，只要逐个比较它们的函数值大小即可。但是，这个方程是否容易求解呢？这取决于ODOLLARfODOLLAR导函数的形式。如果ODOLLARfODOLLAR为简单的线性函数，那么这个问题就是简单的线性最小二乘问题，但是有些导函数可能形式复杂，使得该方程可能不容易求解。求解这个方程需要我们知道关于目标函数的OBACKSLASHtextbfOPENCURLY全局性质CLOSECURLY，而通常这是不大可能的。对于不方便直接求解的最小二乘问题，我们可以用OBACKSLASHtextbfOPENCURLY迭代CLOSECURLY的方式，从一个初始值出发，不断地更新当前的优化变量，使目标函数下降。具体步骤可列写如下：

OBACKSLASHbeginOPENCURLYmdframedCLOSECURLY  
OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 给定某个初始值ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCORE0ODOLLAR。
	OBACKSLASHitem 对于第ODOLLARkODOLLAR次迭代，寻找一个增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR，使得ODOLLAROBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OPLUS OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHright OBACKSLASHOBBOROHAT2OUNDERSCORE2ODOLLAR达到极小值。
	OBACKSLASHitem 若ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR足够小，则停止。
	OBACKSLASHitem 否则，令ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYkOPLUS1CLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOPLUSOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR，返回第2步。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY
OBACKSLASHendOPENCURLYmdframedCLOSECURLY
这让求解OBACKSLASHtextbfOPENCURLY导函数为零CLOSECURLY的问题变成了一个不断OBACKSLASHtextbfOPENCURLY寻找下降增量CLOSECURLYODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR的问题，我们将看到，由于可以对ODOLLARfODOLLAR进行线性化，增量的计算将简单很多。当函数下降直到增量非常小的时候，就认为算法收敛，目标函数达到了一个极小值。在这个过程中，问题在于如何找到每次迭代点的增量，而这是一个局部的问题，我们只需要关心ODOLLARfODOLLAR在迭代值处的局部性质而非全局性质。这类方法在最优化、机器学习等领域应用非常广泛。

接下来我们考察如何寻找这个增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR。这部分知识实际属于数值优化的领域，我们来看一些广泛使用的结果。

OBACKSLASHsubsectionOPENCURLY一阶和二阶梯度法CLOSECURLY
现在考虑第ODOLLARkODOLLAR次迭代，假设我们在ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR处，想要寻到增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR，那么最直观的方式是将目标函数在ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR附近进行泰勒展开：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
FOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOPLUSOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKET OBACKSLASHapprox FOPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKETCLOSECURLY OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKET OHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OPLUS OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHDelta OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOBACKSLASHbmOPENCURLYHCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKET OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
其中ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOLLAR是ODOLLARFOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR关于ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的一阶导数（也叫梯度、OBACKSLASHtextbfOPENCURLY雅可比CLOSECURLY矩阵﹝Jacobian﹞）OBACKSLASHfootnoteOPENCURLY我们把ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR写成列向量，那么它可以和ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR进行内积，得到一个标量。CLOSECURLY，ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR则是二阶导数（OBACKSLASHtextbfOPENCURLY海塞CLOSECURLY﹝Hessian﹞矩阵），它们都在ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR处取值，读者应该在大学本科多元微积分课程中学习过。我们可以选择保留泰勒展开的一阶或二阶项，那么对应的求解方法则称为一阶梯度或二阶梯度法。如果保留一阶梯度，那么取增量为反向的梯度，即可保证函数下降：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOMULTIPLY OASSIGN OMINUS OBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
当然这只是个方向，通常我们还要再指定一个步长ODOLLAROBACKSLASHlambdaODOLLAR。步长可以根据一定的条件来计算OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYWolfe1969CLOSECURLYCLOSECURLY，在机器学习当中也有一些经验性质的方法，但我们不展开谈。这种方法被称为OBACKSLASHtextbfOPENCURLY最速下降法CLOSECURLY。它的直观意义非常简单，只要我们沿着反向梯度方向前进，在一阶（线性）的近似下，目标函数必定会下降。

注意到以上讨论都是在第ODOLLARkODOLLAR次迭代时进行的，并不涉及其他的迭代信息。所以为了简化符号起见，后面我们省略下标ODOLLARkODOLLAR，并认为这些讨论对任意一次迭代都成立。

另一方面，我们可选择保留二阶梯度信息，此时增量方程为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOMULTIPLY OASSIGN OBACKSLASHarg OBACKSLASHmin OBACKSLASHleftOPENBRACKETFOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHDelta OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOBACKSLASHbmOPENCURLYHCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
右侧只含ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的零次、一次和二次项。求右侧等式关于ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的导数并令它为零OBACKSLASHfootnoteOPENCURLY对矩阵求导不熟悉的同学请参考附录B。CLOSECURLY，得到：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbmOPENCURLYJCLOSECURLY OPLUS OBACKSLASHbmOPENCURLYHCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OBACKSLASHbmOPENCURLY0CLOSECURLY OBACKSLASHRightarrow
OBACKSLASHbmOPENCURLYHCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OMINUSOBACKSLASHbmOPENCURLYJCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
求解这个线性方程，就得到了增量。该方法又称为OBACKSLASHtextbfOPENCURLY牛顿法CLOSECURLY。

我们看到，一阶和二阶梯度法都十分直观，只要把函数在迭代点附近进行泰勒展开，并针对更新量做最小化即可。事实上，我们用一个一次或二次的函数近似了原函数，然后用近似函数的最小值来猜测原函数的极小值。只要原目标函数局部看起来像一次或二次函数，这类算法就是成立的（这也是现实当中的情形）。不过，这两种方法也存在它们自身的问题。最速下降法过于贪心，容易走出锯齿路线，反而增加了迭代次数。而牛顿法则需要计算目标函数的ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR矩阵，这在问题规模较大时非常困难，我们通常倾向于避免ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR的计算。对于一般的问题，一些拟牛顿法可以得到较好的结果，而对于最小二乘问题，还有几类更加实用的方法：OBACKSLASHtextbfOPENCURLY高斯牛顿法CLOSECURLY（GaussOMINUSNewton's method）和OBACKSLASHtextbfOPENCURLY列文伯格—马夸尔特方法CLOSECURLY（LevernburgOMINUSMarquardt's method）。

OBACKSLASHsubsectionOPENCURLY高斯牛顿法CLOSECURLY
高斯牛顿法是最优化算法中最简单的方法之一。它的思想是将ODOLLARfOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR进行一阶的泰勒展开。请注意这里不是目标函数ODOLLARFOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR而是ODOLLARfOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR，否则就变成牛顿法了。
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHlabelOPENCURLYeqOCOLONapproximationCLOSECURLY
fOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKET OBACKSLASHapprox fOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
这里ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR为ODOLLARfOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETODOLLAR关于ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的导数，为ODOLLARn OBACKSLASHtimes 1ODOLLAR的列向量。根据前面的框架，当前的目标是寻找增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR，使得ODOLLAROBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHright OBACKSLASHOBBOROHAT2ODOLLAR达到最小。为了求ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR，我们需要解一个线性的最小二乘问题：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOMULTIPLY OASSIGN OBACKSLASHarg OBACKSLASHmathop OPENCURLYOBACKSLASHmin CLOSECURLYOBACKSLASHlimitsOUNDERSCOREOPENCURLYOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY CLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2CLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

这个方程与之前有什么不一样呢？根据极值条件，将上述目标函数对ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR求导，并令导数为零。为此，先展开目标函数的平方项：
OBACKSLASHbeginOPENCURLYalignOMULTIPLYCLOSECURLY
OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2CLOSECURLY OBANDOASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOPENBRACKET OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHOBACKSLASH
OBANDOASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHleftOPENBRACKET OBACKSLASHOBBOR fOPENCURLYOPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOBACKSLASHOBBOROHAT2OUNDERSCORE2 OPLUS 2 fOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OBACKSLASHbmOPENCURLYJCLOSECURLY OPENCURLYOPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHDelta OPENCURLY OBACKSLASHbmOPENCURLYxCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOPENCURLYOBACKSLASHbmOPENCURLYJCLOSECURLY OPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETCLOSECURLY OBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYalignOMULTIPLYCLOSECURLY

求上式关于ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的导数，并令其为零：
OBACKSLASHbeginOPENCURLYdisplaymathCLOSECURLY
OBACKSLASHbmOPENCURLYJCLOSECURLY OPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHbmOPENCURLYJCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OBACKSLASHbmOPENCURLY0CLOSECURLYODOT
OBACKSLASHendOPENCURLYdisplaymathCLOSECURLY

可以得到如下方程组：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHunderbraceOPENCURLYOBACKSLASHbmOPENCURLYJCLOSECURLY OPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHbmOPENCURLYJCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHbmOPENCURLYHCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN  OBACKSLASHunderbraceOPENCURLYOMINUS OBACKSLASHbmOPENCURLYJCLOSECURLY OPENCURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY fOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLYOUNDERSCOREOPENCURLYOBACKSLASHbmOPENCURLYgCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYCLOSEBRACKETCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

这个方程是关于变量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的OBACKSLASHtextbfOPENCURLY线性方程组CLOSECURLY，我们称它为OBACKSLASHtextbfOPENCURLY增量方程CLOSECURLY，也可以称为OBACKSLASHtextbfOPENCURLY高斯牛顿方程CLOSECURLY（GaussOMINUSNewton equation）或者OBACKSLASHtextbfOPENCURLY正规方程CLOSECURLY（Normal equation）。我们把左边的系数定义为ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR，右边定义为ODOLLAROBACKSLASHbmOPENCURLYgCLOSECURLYODOLLAR，那么上式变为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHlabelOPENCURLYeqOCOLONminimizeOMINUSdeltaxCLOSECURLY
OBACKSLASHbmOPENCURLYHCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYgCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
这里把左侧记作ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR是有意义的。对比牛顿法可见，高斯牛顿法用ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOBACKSLASHbmOPENCURLYJCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR OBACKSLASHtextbfOPENCURLY作为牛顿法中二阶Hessian矩阵的近似CLOSECURLY，从而省略了计算ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR的过程。OBACKSLASHtextbfOPENCURLY求解增量方程是整个优化问题的核心所在CLOSECURLY。如果我们能够顺利解出该方程，那么高斯牛顿法的算法步骤可以写成：

OBACKSLASHbeginOPENCURLYmdframedCLOSECURLY
	OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
		OBACKSLASHitem 给定初始值ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCORE0ODOLLAR。
		OBACKSLASHitem 对于第ODOLLARkODOLLAR次迭代，求出当前的雅可比矩阵ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOLLAR和误差ODOLLARfOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSEBRACKETODOLLAR。
		OBACKSLASHitem 求解增量方程：ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OASSIGN OBACKSLASHbmOPENCURLYgCLOSECURLYODOLLAR。
		OBACKSLASHitem 若ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR足够小，则停止。否则，令ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYkOPLUS1CLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOPLUSOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR，返回第2步。
	OBACKSLASHendOPENCURLYenumerateCLOSECURLY
OBACKSLASHendOPENCURLYmdframedCLOSECURLY

从算法步骤中可以看到，增量方程的求解占据着主要地位。只要我们能够顺利解出增量，就能保证目标函数能够正确地下降。

为了求解增量方程，我们需要求解ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYOHATOPENCURLYOMINUS1CLOSECURLYODOLLAR，这需要ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR矩阵可逆，但实际数据中计算得到的ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHbmOPENCURLYJCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR却只有半正定性。也就是说，在使用高斯牛顿法时，可能出现ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOBACKSLASHbmOPENCURLYJCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR为奇异矩阵或者病态（illOMINUScondition）的情况，此时增量的稳定性较差，导致算法不收敛。直观地说，原函数在这个点的局部近似不像一个二次函数。更严重的是，就算我们假设ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR非奇异也非病态，如果我们求出来的步长ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR太大，也会导致我们采用的局部近似式OBACKSLASHeqrefOPENCURLYeqOCOLONapproximationCLOSECURLY不够准确，这样一来我们甚至无法保证它的迭代收敛，哪怕是让目标函数变得更大都是有可能的。

尽管高斯牛顿法有这些缺点，但它依然算是非线性优化方面一种简单有效的方法，值得我们去学习。在非线性优化领域，相当多的算法都可以归结为高斯牛顿法的变种。这些算法都借助了高斯牛顿法的思想并且通过自己的改进修正其缺点。例如一些OBACKSLASHtextbfOPENCURLY线搜索方法CLOSECURLYOPENBRACKETline search methodCLOSEBRACKET加入了一个步长ODOLLAROBACKSLASHalphaODOLLAR，在确定了ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR后进一步找到ODOLLAROBACKSLASHalphaODOLLAR使得ODOLLAROBACKSLASHleftOBACKSLASHOBBOR fOPENBRACKETOBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHalpha OBACKSLASHDelta OBACKSLASHbmOPENCURLY xCLOSECURLYCLOSEBRACKET OBACKSLASHrightOBACKSLASHOBBOROHAT2ODOLLAR达到最小，而不是简单地令ODOLLAROBACKSLASHalpha OASSIGN 1ODOLLAR。

列文伯格—马夸尔特方法在一定程度上修正了这些问题。一般认为它比高斯牛顿法更为健壮，但它的收敛速度可能会比高斯牛顿法更慢，被称为OBACKSLASHtextbfOPENCURLY阻尼牛顿法CLOSECURLY（Damped Newton Method）。

OBACKSLASHsubsectionOPENCURLY列文伯格—马夸尔特方法CLOSECURLY
高斯牛顿法中采用的近似二阶泰勒展开只能在展开点附近有较好的近似效果，所以我们很自然地想到应该给ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR添加一个范围，称为OBACKSLASHtextbfOPENCURLY信赖区域CLOSECURLY（Trust Region）。这个范围定义了在什么情况下二阶近似是有效的，这类方法也称为OBACKSLASHtextbfOPENCURLY信赖区域方法CLOSECURLY（Trust Region Method）。在信赖区域里边，我们认为近似是有效的；出了这个区域，近似可能会出问题。

那么如何确定这个信赖区域的范围呢？一个比较好的方法是根据我们的近似模型跟实际函数之间的差异来确定：如果差异小，说明近似效果好，我们扩大近似的范围；反之，如果差异大，就缩小近似的范围。我们定义一个指标ODOLLAROBACKSLASHrhoODOLLAR来刻画近似的好坏程度：
OBACKSLASHbeginOPENCURLYequationCLOSECURLYOBACKSLASHlabelOPENCURLYeqOCOLON6ODOT24CLOSECURLY
OBACKSLASHrho  OASSIGN OBACKSLASHfracOPENCURLYOPENCURLYfOBACKSLASHleftOPENBRACKET OPENCURLYOBACKSLASHbmOPENCURLYxCLOSECURLY OPLUS OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY  OMINUS OPENCURLYOPENCURLY OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY CLOSECURLYCLOSECURLYCLOSECURLYOPENCURLY OBACKSLASHbmOPENCURLYJCLOSECURLYOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLY OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLY CLOSECURLY ODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
ODOLLAROBACKSLASHrhoODOLLAR的分子是实际函数下降的值，分母是近似模型下降的值。如果ODOLLAROBACKSLASHrhoODOLLAR接近于1，则近似是好的。如果ODOLLAROBACKSLASHrhoODOLLAR太小，说明实际减小的值远少于近似减小的值，则认为近似比较差，需要缩小近似范围。反之，如果ODOLLAROBACKSLASHrhoODOLLAR比较大，则说明实际下降的比预计的更大，我们可以放大近似范围。

于是，我们构建一个改良版的非线性优化框架，该框架会比高斯牛顿法有更好的效果：

OBACKSLASHbeginOPENCURLYmdframedCLOSECURLY
OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 给定初始值ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCORE0ODOLLAR，以及初始优化半径ODOLLAROBACKSLASHmuODOLLAR。
	OBACKSLASHitem 对于第ODOLLARkODOLLAR次迭代，在高斯牛顿法的基础上加上信赖区域，求解：
	OBACKSLASHbeginOPENCURLYequationCLOSECURLYOBACKSLASHlabelOPENCURLYeqOCOLONLMCLOSECURLY
	OBACKSLASHmathop OPENCURLYOBACKSLASHmin CLOSECURLYOBACKSLASHlimitsOUNDERSCOREOPENCURLYOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2CLOSECURLYOCOMMA OBACKSLASHquad OBACKSLASHmathrmOPENCURLYsODOTtODOTCLOSECURLYOBACKSLASHquad OPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYOBACKSLASHbmOPENCURLYDCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2CLOSECURLY OBACKSLASHleqslant OBACKSLASHmu OCOMMA
	OBACKSLASHendOPENCURLYequationCLOSECURLY
	其中ODOLLAROBACKSLASHmuODOLLAR是信赖区域的半径，ODOLLAROBACKSLASHbmOPENCURLYDCLOSECURLYODOLLAR为系数矩阵，将在后文说明。
	OBACKSLASHitem 按式OBACKSLASHeqrefOPENCURLYeqOCOLON6ODOT24CLOSECURLY计算ODOLLAROBACKSLASHrhoODOLLAR。
	OBACKSLASHitem 若ODOLLAROBACKSLASHrho OLESS OBACKSLASHfracOPENCURLY3CLOSECURLYOPENCURLY4CLOSECURLYODOLLAR，则设置ODOLLAROBACKSLASHmu OASSIGN 2 OBACKSLASHmuODOLLAR。
	OBACKSLASHitem 若ODOLLAROBACKSLASHrho OGREAT OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY4CLOSECURLYODOLLAR，则设置ODOLLAROBACKSLASHmu OASSIGN 0ODOT5 OBACKSLASHmuODOLLAR。
	OBACKSLASHitem 如果ODOLLAROBACKSLASHrhoODOLLAR大于某阈值，则认为近似可行。令ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYkOPLUS1CLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOPLUSOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR。
	OBACKSLASHitem 判断算法是否收敛。如不收敛则返回第2步，否则结束。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY
 OBACKSLASHendOPENCURLYmdframedCLOSECURLY

这里近似范围扩大的倍数和阈值都是经验值，可以替换成别的数值。在式OBACKSLASHeqrefOPENCURLYeqOCOLONLMCLOSECURLY中，我们把增量限定于一个半径为ODOLLAROBACKSLASHmuODOLLAR的球中，认为只在这个球内才是有效的。带上ODOLLAROBACKSLASHbmOPENCURLYDCLOSECURLYODOLLAR之后，这个球可以看成一个椭球。在列文伯格提出的优化方法中，把ODOLLAROBACKSLASHbmOPENCURLYDCLOSECURLYODOLLAR取成单位阵ODOLLAROBACKSLASHbmOPENCURLYICLOSECURLYODOLLAR，相当于直接把ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkODOLLAR约束在一个球中。随后，马夸尔特提出将ODOLLAROBACKSLASHbmOPENCURLYDCLOSECURLYODOLLAR取成非负数对角阵——实际中通常用ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOHATT OBACKSLASHbmOPENCURLYJCLOSECURLYODOLLAR的对角元素平方根，使得在梯度小的维度上约束范围更大一些。

不论如何，在列文伯格—马夸尔特优化中，我们都需要解式OBACKSLASHeqrefOPENCURLYeqOCOLONLMCLOSECURLY那样一个子问题来获得梯度。这个子问题是带不等式约束的优化问题，我们用拉格朗日乘子把约束项放到目标函数中，构成拉格朗日函数：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHmathcalOPENCURLYLCLOSECURLYOPENBRACKETOBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkOCOMMA OBACKSLASHlambdaCLOSEBRACKETOASSIGN OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLY OPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYfOBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKET OPLUS OBACKSLASHbmOPENCURLYJCLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightCLOSEBRACKETOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREkCLOSECURLY OBACKSLASHrightOBACKSLASHOBBOROHAT2CLOSECURLY OPLUS OBACKSLASHfracOPENCURLYOBACKSLASHlambdaCLOSECURLYOPENCURLY2CLOSECURLY OBACKSLASHleftOPENBRACKET OBACKSLASHleftOBACKSLASHOBBOR OBACKSLASHbmOPENCURLYDCLOSECURLY OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OBACKSLASHrightOBACKSLASHOBBOROHAT2 OMINUS OBACKSLASHmu OBACKSLASHrightCLOSEBRACKETODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY
这里ODOLLAROBACKSLASHlambdaODOLLAR为拉格朗日乘子。类似于高斯牛顿法中的做法，令该拉格朗日函数关于ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的导数为零，它的核心仍是计算增量的线性方程：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYHCLOSECURLY OPLUSOBACKSLASHlambda OBACKSLASHbmOPENCURLYDCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHbmOPENCURLYDCLOSECURLY OBACKSLASHrightCLOSEBRACKET OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OASSIGN OBACKSLASHbmOPENCURLYgCLOSECURLYODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

可以看到，增量方程相比于高斯牛顿法，多了一项ODOLLAROBACKSLASHlambda OBACKSLASHbmOPENCURLYDCLOSECURLYOHATT OBACKSLASHbmOPENCURLYDCLOSECURLYODOLLAR。如果考虑它的简化形式，即ODOLLAROBACKSLASHbmOPENCURLYDCLOSECURLYOASSIGNOBACKSLASHbmOPENCURLYICLOSECURLYODOLLAR，那么相当于求解OBACKSLASHfootnoteOPENCURLY严谨的读者可能不满意此处的叙述。信赖域原问题的约束条件除了拉格朗日函数求导为零以外，KKT条件还会有一些别的约束：ODOLLAROBACKSLASHlambdaOLESS0ODOLLAR，且ODOLLAROBACKSLASHlambdaOPENBRACKETOBACKSLASHOBBOROBACKSLASHbmOPENCURLYDCLOSECURLY OBACKSLASHDeltaOBACKSLASHbmOPENCURLYxCLOSECURLYOBACKSLASHOBBOROHAT2OMINUSOBACKSLASHmuCLOSEBRACKETOASSIGN0ODOLLAR。但是在LOMINUSM迭代中，我们不妨把它看成在原问题的目标函数上，以ODOLLAROBACKSLASHlambdaODOLLAR为权重的惩罚项。在每一步迭代后，若发现信赖域条件不满足，或者目标函数增加，就增加ODOLLAROBACKSLASHlambdaODOLLAR的权重，直到最终满足信赖域条件。所以，理论上对LOMINUSM算法存在不同的解释，但实际当中我们只关心它是否顺利工作。CLOSECURLY：
OBACKSLASHbeginOPENCURLYdisplaymathCLOSECURLY
OBACKSLASHleftOPENBRACKET OBACKSLASHbmOPENCURLYHCLOSECURLY OPLUSOBACKSLASHlambda OBACKSLASHbmOPENCURLYICLOSECURLY OBACKSLASHrightCLOSEBRACKET OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OASSIGN OBACKSLASHbmOPENCURLYgCLOSECURLYODOT
OBACKSLASHendOPENCURLYdisplaymathCLOSECURLY

我们看到，当参数ODOLLAROBACKSLASHlambdaODOLLAR比较小时，ODOLLAROBACKSLASHbmOPENCURLYHCLOSECURLYODOLLAR占主要地位，这说明二次近似模型在该范围内是比较好的，列文伯格—马夸尔特方法更接近于高斯牛顿法。另一方面，当ODOLLAROBACKSLASHlambdaODOLLAR比较大时，ODOLLAROBACKSLASHlambda OBACKSLASHbmOPENCURLYICLOSECURLYODOLLAR占据主要地位，列文伯格—马夸尔特方法更接近于一阶梯度下降法（即最速下降），这说明附近的二次近似不够好。列文伯格—马夸尔特方法的求解方式，可在一定程度上避免线性方程组的系数矩阵的非奇异和病态问题，提供更稳定、更准确的增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR。

在实际中，还存在许多其他的方式来求解增量，例如DogOMINUSLegOBACKSLASHciteOPENCURLYNocedal2006CLOSECURLY等方法。我们在这里所介绍的，只是最常见而且最基本的方法，也是视觉SLAM中用得最多的方法。实际问题中，我们通常选择高斯牛顿法或列文伯格—马夸尔特方法其中之一作为梯度下降策略。当问题性质较好时，用高斯牛顿。如果问题接近病态，则用列文伯格—马夸尔特方法。

OBACKSLASHsubsectionOPENCURLY小结CLOSECURLY
由于不希望这本书变成一本让人觉得头疼的数学教科书，所以这里只罗列了最常见的两种非线性优化方案——高斯牛顿法和列文伯格—马夸尔特方法。我们避开了许多数学性质上的讨论。如果读者对优化感兴趣，可以进一步阅读专门介绍数值优化的书籍（这是一个很大的课题）OBACKSLASHciteOPENCURLYNocedal2006CLOSECURLY。以高斯牛顿法和列文伯格—马夸尔特方法为代表的优化方法，在很多开源的优化库中都已经实现并提供给用户，我们会在下文进行实验。最优化是处理许多实际问题的基本数学工具，不光在视觉SLAM中起着核心作用，在类似于深度学习等其他领域，它也是求解问题的核心方法之一（深度学习数据量很大，以一阶方法为主）。我们希望读者能够根据自身能力，去了解更多的最优化算法。

也许你发现了，无论是高斯牛顿法还是列文伯格—马夸尔特方法，在做最优化计算时，都需要提供变量的初始值。你也许会问到，这个初始值能否随意设置？当然不是。实际上非线性优化的所有迭代求解方案，都需要用户来提供一个良好的初始值。由于目标函数太复杂，导致在求解空间上的变化难以预测，对问题提供不同的初始值往往会导致不同的计算结果。这种情况是非线性优化的通病：大多数算法都容易陷入局部极小值。因此，无论是哪类科学问题，我们提供初始值都应该有科学依据，例如视觉SLAM问题中，我们会用ICP、PnP之类的算法提供优化初始值。总之，一个良好的初始值对最优化问题非常重要！

也许读者还会对上面提到的最优化产生疑问：如何求解线性增量方程组呢？我们只讲到了增量方程是一个线性方程，但是直接对系数矩阵进行求逆岂不是要进行大量的计算？当然不是。在视觉SLAM算法里，经常遇到ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的维度大到好几百或者上千，如果你是要做大规模的视觉三维重建，就会经常发现这个维度可以轻易达到几十万甚至更高的级别。要对那么大个矩阵进行求逆是大多数处理器无法负担的，因此存在着许多针对线性方程组的数值求解方法。在不同的领域有不同的求解方式，但几乎没有一种方式是直接求系数矩阵的逆，我们会采用矩阵分解的方法来解线性方程，例如QR、Cholesky等分解方法。这些方法通常在矩阵论等教科书中可以找到，我们不多加介绍。

幸运的是，视觉SLAM里这个矩阵往往有特定的稀疏形式，这为实时求解优化问题提供了可能性。我们将在第9讲中详细介绍它的原理。利用稀疏形式的消元、分解，最后再进行求解增量，会让求解的效率大大提高。在很多开源的优化库上，维度为一万多的变量在一般的PC上就可以在几秒甚至更短的时间内被求解出来，其原因也是用了更加高级的数学工具。视觉SLAM算法现在能够实时地实现，也多亏了系数矩阵是稀疏的，如果矩阵是稠密的，恐怕优化这类视觉SLAM算法就不会被学界广泛采纳了OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYLourakis2009OCOMMA Sibley2009aOCOMMA Triggs2000CLOSECURLYCLOSECURLY。

OBACKSLASHsectionOPENCURLY实践：曲线拟合问题CLOSECURLY
OBACKSLASHsubsectionOPENCURLY手写高斯牛顿法CLOSECURLY
接下来我们用一个简单的例子来说明如何求解最小二乘问题。我们将演示如何手写高斯牛顿法，然后再介绍如何使用优化库求解此问题。对于同一个问题，这些实现方式会得到同样的结果，因为它们的核心算法是一样的。

考虑一条满足以下方程的曲线：
OBACKSLASHOPENSQUARE
y OASSIGN OBACKSLASHexpOPENBRACKET axOHAT2 OPLUS bx OPLUS c CLOSEBRACKET OPLUS wOCOMMA
OBACKSLASHCLOSESQUARE
其中ODOLLARaOCOMMAbOCOMMAcODOLLAR为曲线的参数，ODOLLARwODOLLAR为高斯噪声，满足ODOLLARw OBACKSLASHsim OPENBRACKET0OCOMMA OBACKSLASHsigmaOHAT2CLOSEBRACKETODOLLAR。我们故意选择了这样一个非线性模型，使问题不至于太简单。现在，假设我们有ODOLLARNODOLLAR个关于ODOLLARxOCOMMAyODOLLAR的观测数据点，想根据这些数据点求出曲线的参数。那么，可以求解下面的最小二乘问题以估计曲线参数：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHmin OBACKSLASHlimitsOUNDERSCOREOPENCURLYaOCOMMAbOCOMMAcCLOSECURLY OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREOPENCURLYi OASSIGN 1CLOSECURLYOHATN OPENCURLYOPENCURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYOPENCURLYyOUNDERSCOREiCLOSECURLY OMINUS OBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLYaxOUNDERSCOREiOHAT2 OPLUS bxOUNDERSCOREi OPLUS cCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightOBACKSLASHOBBORCLOSECURLYOHAT2CLOSECURLYCLOSECURLY ODOT
OBACKSLASHendOPENCURLYequationCLOSECURLY

请注意，在这个问题中，待估计的变量是ODOLLARaOCOMMAbOCOMMAcODOLLAR，而不是ODOLLARxODOLLAR。我们的程序里先根据模型生成ODOLLARxOCOMMAyODOLLAR的真值，然后在真值中添加高斯分布的噪声。随后，使用高斯牛顿法来从带噪声的数据拟合参数模型。定义误差为OCOLON
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
eOUNDERSCOREi OASSIGN yOUNDERSCOREi OMINUS OBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLYaxOUNDERSCOREiOHAT2 OPLUS bxOUNDERSCOREi OPLUS cCLOSECURLY OBACKSLASHrightCLOSEBRACKETOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
那么可以求出每个误差项对于状态变量的导数：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYalignedCLOSECURLY
OBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial OPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial aCLOSECURLYCLOSECURLY OBANDOASSIGN  OMINUS xOUNDERSCOREiOHAT2OBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLYaxOUNDERSCOREiOHAT2 OPLUS bOPENCURLYxOUNDERSCOREiCLOSECURLY OPLUS cCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHOBACKSLASH
OBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial eOUNDERSCOREiCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial bCLOSECURLYCLOSECURLY OBANDOASSIGN  OMINUS OPENCURLYxOUNDERSCOREiCLOSECURLYOBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLYaxOUNDERSCOREiOHAT2 OPLUS bOPENCURLYxOUNDERSCOREiCLOSECURLY OPLUS cCLOSECURLY OBACKSLASHrightCLOSEBRACKETOBACKSLASHOBACKSLASH
OBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial OPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial cCLOSECURLYCLOSECURLY OBANDOASSIGN  OMINUS OBACKSLASHexp OBACKSLASHleftOPENBRACKET OPENCURLYaxOUNDERSCOREiOHAT2 OPLUS bOPENCURLYxOUNDERSCOREiCLOSECURLY OPLUS cCLOSECURLY OBACKSLASHrightCLOSEBRACKET
OBACKSLASHendOPENCURLYalignedCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY
于是ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOUNDERSCOREi OASSIGN OBACKSLASHleftOPENSQUAREOBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial OPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial aCLOSECURLYCLOSECURLYOCOMMAOBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial OPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial bCLOSECURLYCLOSECURLYOCOMMAOBACKSLASHfracOPENCURLYOPENCURLYOBACKSLASHpartial OPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYCLOSECURLYOPENCURLYOPENCURLYOBACKSLASHpartial cCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSESQUAREOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYODOLLAR，高斯牛顿法的增量方程为：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHleftOPENBRACKETOBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREOPENCURLYi OASSIGN 1CLOSECURLYOHATOPENCURLY100CLOSECURLY OPENCURLYOBACKSLASHbmOPENCURLYJCLOSECURLYOUNDERSCOREiOPENCURLYOPENBRACKETOBACKSLASHsigmaOHAT2CLOSEBRACKETOHATOPENCURLY OMINUS 1CLOSECURLYCLOSECURLYOPENCURLYOBACKSLASHbmOPENCURLYJCLOSECURLYOUNDERSCOREiCLOSECURLYCLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHrightCLOSEBRACKET OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OASSIGN OBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREOPENCURLYi OASSIGN 1CLOSECURLYOHATOPENCURLY100CLOSECURLY OPENCURLY OMINUS OPENCURLYOBACKSLASHbmOPENCURLYJCLOSECURLYOUNDERSCOREiCLOSECURLYOPENCURLYOPENBRACKETOBACKSLASHsigmaOHAT2CLOSEBRACKETOHATOPENCURLY OMINUS 1CLOSECURLYCLOSECURLYOPENCURLYeOUNDERSCOREiCLOSECURLYCLOSECURLYOCOMMA
OBACKSLASHendOPENCURLYequationCLOSECURLY
当然我们也可以选择把所有的ODOLLAROBACKSLASHbmOPENCURLYJCLOSECURLYOUNDERSCOREiODOLLAR排成一列，将这个方程写成矩阵形式，不过它的含义与求和形式是一致的。下面的代码演示了这个过程是如何进行的。
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNshOCOMMAcaptionOASSIGNslambook2ODIVIDEch6ODIVIDEgaussNewtonODOTcppCLOSESQUARE
OSINGLEHASHinclude OGREATiostreamOLESS
OSINGLEHASHinclude OGREATopencv2ODIVIDEopencvODOThppOLESS
OSINGLEHASHinclude OGREATEigenODIVIDECoreOLESS
OSINGLEHASHinclude OGREATEigenODIVIDEDenseOLESS

using namespace stdOSEMICOLON
using namespace EigenOSEMICOLON

int mainOPENBRACKETint argcOCOMMA char OMULTIPLYOMULTIPLYargvCLOSEBRACKET OPENCURLY
    double ar OASSIGN 1ODOT0OCOMMA br OASSIGN 2ODOT0OCOMMA cr OASSIGN 1ODOT0OSEMICOLON         ODIVIDEODIVIDE 真实参数值
    double ae OASSIGN 2ODOT0OCOMMA be OASSIGN OMINUS1ODOT0OCOMMA ce OASSIGN 5ODOT0OSEMICOLON        ODIVIDEODIVIDE 估计参数值
    int N OASSIGN 100OSEMICOLON                                 ODIVIDEODIVIDE 数据点
    double wOUNDERSCOREsigma OASSIGN 1ODOT0OSEMICOLON                        ODIVIDEODIVIDE 噪声Sigma值
    double invOUNDERSCOREsigma OASSIGN 1ODOT0 ODIVIDE wOUNDERSCOREsigmaOSEMICOLON
    cvOCOLONOCOLONRNG rngOSEMICOLON                                 ODIVIDEODIVIDE OpenCV随机数产生器
    
    vectorOGREATdoubleOLESS xOUNDERSCOREdataOCOMMA yOUNDERSCOREdataOSEMICOLON      ODIVIDEODIVIDE 数据
    for OPENBRACKETint i OASSIGN 0OSEMICOLON i OGREAT NOSEMICOLON iOPLUSOPLUSCLOSEBRACKET OPENCURLY
        double x OASSIGN i ODIVIDE 100ODOT0OSEMICOLON
        xOUNDERSCOREdataODOTpushOUNDERSCOREbackOPENBRACKETxCLOSEBRACKETOSEMICOLON
        yOUNDERSCOREdataODOTpushOUNDERSCOREbackOPENBRACKETexpOPENBRACKETar OMULTIPLY x OMULTIPLY x OPLUS br OMULTIPLY x OPLUS crCLOSEBRACKET OPLUS rngODOTgaussianOPENBRACKETwOUNDERSCOREsigma OMULTIPLY wOUNDERSCOREsigmaCLOSEBRACKETCLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 开始GaussOMINUSNewton迭代
    int iterations OASSIGN 100OSEMICOLON    ODIVIDEODIVIDE 迭代次数
    double cost OASSIGN 0OCOMMA lastCost OASSIGN 0OSEMICOLON  ODIVIDEODIVIDE 本次迭代的cost和上一次迭代的cost
    
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t1 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    for OPENBRACKETint iter OASSIGN 0OSEMICOLON iter OGREAT iterationsOSEMICOLON iterOPLUSOPLUSCLOSEBRACKET OPENCURLY
        
        Matrix3d H OASSIGN Matrix3dOCOLONOCOLONZeroOPENBRACKETCLOSEBRACKETOSEMICOLON             ODIVIDEODIVIDE Hessian OASSIGN JOHATT WOHATOPENCURLYOMINUS1CLOSECURLY J in GaussOMINUSNewton
        Vector3d b OASSIGN Vector3dOCOLONOCOLONZeroOPENBRACKETCLOSEBRACKETOSEMICOLON             ODIVIDEODIVIDE bias
        cost OASSIGN 0OSEMICOLON
        
        for OPENBRACKETint i OASSIGN 0OSEMICOLON i OGREAT NOSEMICOLON iOPLUSOPLUSCLOSEBRACKET OPENCURLY
            double xi OASSIGN xOUNDERSCOREdataOPENSQUAREiCLOSESQUAREOCOMMA yi OASSIGN yOUNDERSCOREdataOPENSQUAREiCLOSESQUAREOSEMICOLON  ODIVIDEODIVIDE 第i个数据点
            double error OASSIGN yi OMINUS expOPENBRACKETae OMULTIPLY xi OMULTIPLY xi OPLUS be OMULTIPLY xi OPLUS ceCLOSEBRACKETOSEMICOLON
            Vector3d JOSEMICOLON ODIVIDEODIVIDE 雅可比矩阵
            JOPENSQUARE0CLOSESQUARE OASSIGN OMINUSxi OMULTIPLY xi OMULTIPLY expOPENBRACKETae OMULTIPLY xi OMULTIPLY xi OPLUS be OMULTIPLY xi OPLUS ceCLOSEBRACKETOSEMICOLON  ODIVIDEODIVIDE deODIVIDEda
            JOPENSQUARE1CLOSESQUARE OASSIGN OMINUSxi OMULTIPLY expOPENBRACKETae OMULTIPLY xi OMULTIPLY xi OPLUS be OMULTIPLY xi OPLUS ceCLOSEBRACKETOSEMICOLON  ODIVIDEODIVIDE deODIVIDEdb
            JOPENSQUARE2CLOSESQUARE OASSIGN OMINUSexpOPENBRACKETae OMULTIPLY xi OMULTIPLY xi OPLUS be OMULTIPLY xi OPLUS ceCLOSEBRACKETOSEMICOLON  ODIVIDEODIVIDE deODIVIDEdc
            
            H OPLUSOASSIGN invOUNDERSCOREsigma OMULTIPLY invOUNDERSCOREsigma OMULTIPLY J OMULTIPLY JODOTtransposeOPENBRACKETCLOSEBRACKETOSEMICOLON
            b OPLUSOASSIGN OMINUSinvOUNDERSCOREsigma OMULTIPLY invOUNDERSCOREsigma OMULTIPLY error OMULTIPLY JOSEMICOLON
            
            cost OPLUSOASSIGN error OMULTIPLY errorOSEMICOLON
        CLOSECURLY
        
        ODIVIDEODIVIDE 求解线性方程 HxOASSIGNb
        Vector3d dx OASSIGN HODOTldltOPENBRACKETCLOSEBRACKETODOTsolveOPENBRACKETbCLOSEBRACKETOSEMICOLON
        if OPENBRACKETisnanOPENBRACKETdxOPENSQUARE0CLOSESQUARECLOSEBRACKETCLOSEBRACKET OPENCURLY
            cout OGREATOGREAT "result is nanONOT" OGREATOGREAT endlOSEMICOLON
            breakOSEMICOLON
        CLOSECURLY
        
        if OPENBRACKETiter OLESS 0 OBANDOBAND cost OLESSOASSIGN lastCostCLOSEBRACKET OPENCURLY
            cout OGREATOGREAT "costOCOLON " OGREATOGREAT cost OGREATOGREAT "OLESSOASSIGN last costOCOLON " OGREATOGREAT lastCost OGREATOGREAT "OCOMMA breakODOT" OGREATOGREAT endlOSEMICOLON
            breakOSEMICOLON
        CLOSECURLY
        
        ae OPLUSOASSIGN dxOPENSQUARE0CLOSESQUAREOSEMICOLON
        be OPLUSOASSIGN dxOPENSQUARE1CLOSESQUAREOSEMICOLON
        ce OPLUSOASSIGN dxOPENSQUARE2CLOSESQUAREOSEMICOLON
        
        lastCost OASSIGN costOSEMICOLON
        
        cout OGREATOGREAT "total costOCOLON " OGREATOGREAT cost OGREATOGREAT "OCOMMA OBACKSLASHtOBACKSLASHtupdateOCOLON " OGREATOGREAT dxODOTtransposeOPENBRACKETCLOSEBRACKET OGREATOGREAT
          "OBACKSLASHtOBACKSLASHtestimated paramsOCOLON " OGREATOGREAT ae OGREATOGREAT "OCOMMA" OGREATOGREAT be OGREATOGREAT "OCOMMA" OGREATOGREAT ce OGREATOGREAT endlOSEMICOLON
    CLOSECURLY
    
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t2 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    chronoOCOLONOCOLONdurationOGREATdoubleOLESS timeOUNDERSCOREused OASSIGN chronoOCOLONOCOLONdurationOUNDERSCOREcastOGREATchronoOCOLONOCOLONdurationOGREATdoubleOLESSOLESSOPENBRACKETt2 OMINUS t1CLOSEBRACKETOSEMICOLON
    cout OGREATOGREAT "solve time cost OASSIGN " OGREATOGREAT timeOUNDERSCOREusedODOTcountOPENBRACKETCLOSEBRACKET OGREATOGREAT " secondsODOT " OGREATOGREAT endlOSEMICOLON
    cout OGREATOGREAT "estimated abc OASSIGN " OGREATOGREAT ae OGREATOGREAT "OCOMMA " OGREATOGREAT be OGREATOGREAT "OCOMMA " OGREATOGREAT ce OGREATOGREAT endlOSEMICOLON
    return 0OSEMICOLON
CLOSECURLY
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

在这个例子中，我们演示了如何对一个简单的拟合问题进行迭代优化。通过自己手写的代码，很容易看清楚整个优化的流程。该程序输出每一步迭代的目标函数值和更新量，如下：
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNshOCOMMAcaptionOASSIGN终端输出：CLOSESQUARE
ODIVIDEhomeODIVIDExiangODIVIDECodeODIVIDEslambook2ODIVIDEch6ODIVIDEcmakeOMINUSbuildOMINUSdebugODIVIDEgaussNewton
total costOCOLON 3ODOT19575eOPLUS06OCOMMA 		updateOCOLON 0ODOT0455771  0ODOT078164 OMINUS0ODOT985329		estimated paramsOCOLON 2ODOT04558OCOMMAOMINUS0ODOT921836OCOMMA4ODOT01467
total costOCOLON 376785OCOMMA 		updateOCOLON  0ODOT065762  0ODOT224972 OMINUS0ODOT962521		estimated paramsOCOLON 2ODOT11134OCOMMAOMINUS0ODOT696864OCOMMA3ODOT05215
total costOCOLON 35673ODOT6OCOMMA 		updateOCOLON OMINUS0ODOT0670241   0ODOT617616  OMINUS0ODOT907497		estimated paramsOCOLON 2ODOT04432OCOMMAOMINUS0ODOT0792484OCOMMA2ODOT14465
total costOCOLON 2195ODOT01OCOMMA 		updateOCOLON OMINUS0ODOT522767   1ODOT19192 OMINUS0ODOT756452		estimated paramsOCOLON 1ODOT52155OCOMMA1ODOT11267OCOMMA1ODOT3882
total costOCOLON 174ODOT853OCOMMA 		updateOCOLON OMINUS0ODOT537502  0ODOT909933 OMINUS0ODOT386395		estimated paramsOCOLON 0ODOT984045OCOMMA2ODOT0226OCOMMA1ODOT00181
total costOCOLON 102ODOT78OCOMMA 		updateOCOLON OMINUS0ODOT0919666   0ODOT147331 OMINUS0ODOT0573675		estimated paramsOCOLON 0ODOT892079OCOMMA2ODOT16994OCOMMA0ODOT944438
total costOCOLON 101ODOT937OCOMMA 		updateOCOLON OMINUS0ODOT00117081  0ODOT00196749 OMINUS0ODOT00081055		estimated paramsOCOLON 0ODOT890908OCOMMA2ODOT1719OCOMMA0ODOT943628
total costOCOLON 101ODOT937OCOMMA 		updateOCOLON   3ODOT4312eOMINUS06 OMINUS4ODOT28555eOMINUS06  1ODOT08348eOMINUS06		estimated paramsOCOLON 0ODOT890912OCOMMA2ODOT1719OCOMMA0ODOT943629
total costOCOLON 101ODOT937OCOMMA 		updateOCOLON OMINUS2ODOT01204eOMINUS08  2ODOT68928eOMINUS08 OMINUS7ODOT86602eOMINUS09		estimated paramsOCOLON 0ODOT890912OCOMMA2ODOT1719OCOMMA0ODOT943629
costOCOLON 101ODOT937OLESSOASSIGN last costOCOLON 101ODOT937OCOMMA breakODOT
solve time cost OASSIGN 0ODOT000212903 secondsODOT
estimated abc OASSIGN 0ODOT890912OCOMMA 2ODOT1719OCOMMA 0ODOT943629
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY
易见整个问题的目标函数在迭代9次之后趋近收敛，更新量趋近于零。最终估计的值与真值接近，函数图像如OBACKSLASHautorefOPENCURLYfigOCOLONceresOMINUSfittingCLOSECURLY所示。在我的机器上（我的CPU是i7OMINUS8700），优化用时约0ODOT2个毫秒。下面我们尝试使用优化库来完成同样的任务。

OBACKSLASHbeginOPENCURLYfigureCLOSECURLYOPENSQUAREONOThtCLOSESQUARE
    OBACKSLASHcentering
    OBACKSLASHincludegraphicsOPENSQUAREwidthOASSIGN0ODOT8OBACKSLASHtextwidthCLOSESQUAREOPENCURLYoptimizationODIVIDEceresFittingODOTpdfCLOSECURLY
    OBACKSLASHcaptionOPENCURLY噪声ODOLLAROBACKSLASHsigmaOASSIGN1ODOLLAR时的曲线拟合结果。真实模型和估计模型非常接近。CLOSECURLY
    OBACKSLASHlabelOPENCURLYfigOCOLONceresOMINUSfittingCLOSECURLY
OBACKSLASHendOPENCURLYfigureCLOSECURLY

OBACKSLASHsubsectionOPENCURLY使用Ceres进行曲线拟合CLOSECURLY
本节向大家介绍两个COPLUSOPLUS的优化库：来自谷歌的Ceres库OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYCeresCLOSECURLYCLOSECURLY以及基于图优化的g2o库OBACKSLASHtextsuperscriptOPENCURLYOBACKSLASHciteOPENCURLYKummerle2011CLOSECURLYCLOSECURLY。由于g2o的使用还需要介绍一点图优化的相关知识，所以我们先来介绍Ceres，然后介绍一些图优化理论，最后来讲g2o。由于优化算法在之后的“视觉里程计”和“后端”中都会出现，所以请读者务必掌握优化算法的意义，理解程序的内容。

OBACKSLASHsubsubsectionOPENCURLYCeres简介CLOSECURLY
Google Ceres是一个广泛使用的最小二乘问题求解库。在Ceres中，我们作为用户，只需按照一定步骤定义待解的优化问题，然后交给求解器计算即可。Ceres求解的最小二乘问题最一般的形式如下（带边界的核函数最小二乘）：
OBACKSLASHbeginOPENCURLYequationCLOSECURLY
OBACKSLASHbeginOPENCURLYarrayCLOSECURLYOPENCURLYllCLOSECURLY
OBACKSLASHmin OBACKSLASHlimitsOUNDERSCOREx OBACKSLASHquad OBAND OBACKSLASHfracOPENCURLY1CLOSECURLYOPENCURLY2CLOSECURLYOBACKSLASHsumOBACKSLASHlimitsOUNDERSCOREi OPENCURLYOPENCURLYOBACKSLASHrho OUNDERSCOREiCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYOPENCURLYOBACKSLASHleftOBACKSLASHOBBOR OPENCURLYOPENCURLYfOUNDERSCOREiCLOSECURLYOBACKSLASHleftOPENBRACKET OPENCURLYOPENCURLYxOUNDERSCOREOPENCURLYOPENCURLYiOUNDERSCORE1CLOSECURLYCLOSECURLYCLOSECURLYOCOMMA OBACKSLASHcdots OPENCURLYxOUNDERSCOREOPENCURLYOPENCURLYiOUNDERSCOREnCLOSECURLYCLOSECURLYCLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHrightOBACKSLASHOBBORCLOSECURLYOHAT2CLOSECURLYCLOSECURLY OBACKSLASHrightCLOSEBRACKETCLOSECURLY OBACKSLASHOBACKSLASH
OBACKSLASHmathrmOPENCURLYsODOTtODOTCLOSECURLY OBACKSLASHquad OBAND OPENCURLYlOUNDERSCOREjCLOSECURLY OBACKSLASHleqslant OPENCURLYxOUNDERSCOREjCLOSECURLY OBACKSLASHleqslant OPENCURLYuOUNDERSCOREjCLOSECURLYODOT
OBACKSLASHendOPENCURLYarrayCLOSECURLY
OBACKSLASHendOPENCURLYequationCLOSECURLY

在这个问题中，ODOLLARxOUNDERSCORE1OCOMMA OBACKSLASHcdotsOCOMMA xOUNDERSCOREnODOLLAR为优化变量，又称OBACKSLASHtextbfOPENCURLY参数块CLOSECURLY（Parameter blocks），ODOLLARfOUNDERSCOREiODOLLAR称为OBACKSLASHtextbfOPENCURLY代价函数CLOSECURLY（Cost function），也称为残差块（Residual blocks），在SLAM中亦可理解为误差项。ODOLLARlOUNDERSCOREjODOLLAR和ODOLLARuOUNDERSCOREjODOLLAR为第ODOLLARjODOLLAR个优化变量的上限和下限。在最简单的情况下，取ODOLLARlOUNDERSCOREj OASSIGN OMINUSOBACKSLASHinftyOCOMMA uOUNDERSCOREjOASSIGNOBACKSLASHinftyODOLLAR（不限制优化变量的边界）。此时，目标函数由许多平方项经过一个OBACKSLASHtextbfOPENCURLY核函数CLOSECURLYODOLLAROBACKSLASHrhoOPENBRACKETOBACKSLASHcdotCLOSEBRACKETODOLLAR之后求和组成OBACKSLASHfootnoteOPENCURLY核函数的详细讨论见第9讲。CLOSECURLY。同样，可以取ODOLLAROBACKSLASHrhoODOLLAR为恒等函数，那么目标函数即为许多项的平方和，我们就得到了无约束的最小二乘问题，和先前介绍的理论是一致的。

为了让Ceres帮我们求解这个问题，我们需要做以下几件事：
OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
OBACKSLASHitem 定义每个参数块。参数块通常为平凡的向量，但是在SLAM里也可以定义成四元数、李代数这种特殊的结构。如果是向量，那么我们需要为每个参数块分配一个double数组，来存储变量的值。
OBACKSLASHitem 然后，定义残差块的计算方式。残差块通常关联若干个参数块，对它们进行一些自定义的计算，然后返回残差值。Ceres对它们求平方和之后，作为目标函数的值。
OBACKSLASHitem 残差块往往也需要定义雅可比的计算方式。在Ceres中，你可以使用它提供的“自动求导”功能，也可以手动指定雅可比的计算过程。如果要使用自动求导，那么残差块需要按照特定的写法来书写：残差的计算过程应该是一个带模板的括号运算符。这一点我们通过例子来说明。
OBACKSLASHitem 最后，把所有的参数块和残差块加入Ceres定义的Problem对象中，调用Solve函数求解即可。求解之前，我们可以传入一些配置信息，例如迭代次数、终止条件等，也可以使用默认的配置。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY
下面，我们来实际操作一下Ceres求解曲线拟合问题，理解优化的过程。

OBACKSLASHsubsubsectionOPENCURLY安装CeresCLOSECURLY
为了使用Ceres，我们需要对它进行编译安装。Ceres的github地址为：OBACKSLASHurlOPENCURLYhttpsOCOLONODIVIDEODIVIDEgithubODOTcomODIVIDEceresOMINUSsolverODIVIDEceresOMINUSsolverCLOSECURLY，不过你也可以直接使用本书代码3rdparty目录里的Ceres，这样你将和我使用完全一样的版本。

与之前碰到的库一样，Ceres是一个cmake工程。先来安装它的依赖项，在Ubuntu中可以用aptOMINUSget安装，主要是谷歌自己使用的一些日志和测试工具：
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNshOCOMMAcaptionOASSIGN终端输入：CLOSESQUARE
sudo aptOMINUSget install liblapackOMINUSdev libsuitesparseOMINUSdev libcxsparse3 libgflagsOMINUSdev libgoogleOMINUSglogOMINUSdev libgtestOMINUSdev 
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

然后，进入Ceres库目录下，使用cmake编译并安装它。这个过程我们已经做过很多遍了，此处不再赘述。安装完成后，在ODIVIDEusrODIVIDElocalODIVIDEincludeODIVIDEceres下找到Ceres的头文件，并在ODIVIDEusrODIVIDElocalODIVIDElibODIVIDE下找到名为libceresODOTa的库文件。有了这些文件，就可以使用Ceres进行优化计算了。

OBACKSLASHsubsubsectionOPENCURLY使用Ceres拟合曲线CLOSECURLY
下面的代码演示了如何使用Ceres求解同样的问题。

OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNcOPLUSOPLUSOCOMMAcaptionOASSIGNslambookODIVIDEch6ODIVIDEceresCurveFittingODOTcppCLOSESQUARE
OSINGLEHASHinclude OGREATiostreamOLESS
OSINGLEHASHinclude OGREATopencv2ODIVIDEcoreODIVIDEcoreODOThppOLESS
OSINGLEHASHinclude OGREATceresODIVIDEceresODOThOLESS
OSINGLEHASHinclude OGREATchronoOLESS

using namespace stdOSEMICOLON

ODIVIDEODIVIDE 代价函数的计算模型
struct CURVEOUNDERSCOREFITTINGOUNDERSCORECOST OPENCURLY
    CURVEOUNDERSCOREFITTINGOUNDERSCORECOSTOPENBRACKETdouble xOCOMMA double yCLOSEBRACKET OCOLON OUNDERSCORExOPENBRACKETxCLOSEBRACKETOCOMMA OUNDERSCOREyOPENBRACKETyCLOSEBRACKET OPENCURLYCLOSECURLY
    
    ODIVIDEODIVIDE 残差的计算
    templateOGREATtypename TOLESS
    bool operatorOPENBRACKETCLOSEBRACKETOPENBRACKET
        const T OMULTIPLYconst abcOCOMMA ODIVIDEODIVIDE 模型参数，有3维
        T OMULTIPLYresidualCLOSEBRACKET const OPENCURLY
        ODIVIDEODIVIDE yOMINUSexpOPENBRACKETaxOHAT2OPLUSbxOPLUScCLOSEBRACKET
        residualOPENSQUARE0CLOSESQUARE OASSIGN TOPENBRACKETOUNDERSCOREyCLOSEBRACKET OMINUS ceresOCOLONOCOLONexpOPENBRACKETabcOPENSQUARE0CLOSESQUARE OMULTIPLY TOPENBRACKETOUNDERSCORExCLOSEBRACKET OMULTIPLY TOPENBRACKETOUNDERSCORExCLOSEBRACKET OPLUS abcOPENSQUARE1CLOSESQUARE OMULTIPLY TOPENBRACKETOUNDERSCORExCLOSEBRACKET OPLUS abcOPENSQUARE2CLOSESQUARECLOSEBRACKETOSEMICOLON
        return trueOSEMICOLON
    CLOSECURLY
    
    const double OUNDERSCORExOCOMMA OUNDERSCOREyOSEMICOLON    ODIVIDEODIVIDE xOCOMMAy数据
CLOSECURLYOSEMICOLON

int mainOPENBRACKETint argcOCOMMA char OMULTIPLYOMULTIPLYargvCLOSEBRACKET OPENCURLY
    double ar OASSIGN 1ODOT0OCOMMA br OASSIGN 2ODOT0OCOMMA cr OASSIGN 1ODOT0OSEMICOLON         ODIVIDEODIVIDE 真实参数值
    double ae OASSIGN 2ODOT0OCOMMA be OASSIGN OMINUS1ODOT0OCOMMA ce OASSIGN 5ODOT0OSEMICOLON        ODIVIDEODIVIDE 估计参数值
    int N OASSIGN 100OSEMICOLON                                 ODIVIDEODIVIDE 数据点
    double wOUNDERSCOREsigma OASSIGN 1ODOT0OSEMICOLON                        ODIVIDEODIVIDE 噪声Sigma值
    double invOUNDERSCOREsigma OASSIGN 1ODOT0 ODIVIDE wOUNDERSCOREsigmaOSEMICOLON
    cvOCOLONOCOLONRNG rngOSEMICOLON                                 ODIVIDEODIVIDE OpenCV随机数产生器
    
    vectorOGREATdoubleOLESS xOUNDERSCOREdataOCOMMA yOUNDERSCOREdataOSEMICOLON      ODIVIDEODIVIDE 数据
    for OPENBRACKETint i OASSIGN 0OSEMICOLON i OGREAT NOSEMICOLON iOPLUSOPLUSCLOSEBRACKET OPENCURLY
        double x OASSIGN i ODIVIDE 100ODOT0OSEMICOLON
        xOUNDERSCOREdataODOTpushOUNDERSCOREbackOPENBRACKETxCLOSEBRACKETOSEMICOLON
        yOUNDERSCOREdataODOTpushOUNDERSCOREbackOPENBRACKETexpOPENBRACKETar OMULTIPLY x OMULTIPLY x OPLUS br OMULTIPLY x OPLUS crCLOSEBRACKET OPLUS rngODOTgaussianOPENBRACKETwOUNDERSCOREsigma OMULTIPLY wOUNDERSCOREsigmaCLOSEBRACKETCLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    double abcOPENSQUARE3CLOSESQUARE OASSIGN OPENCURLYaeOCOMMA beOCOMMA ceCLOSECURLYOSEMICOLON
    
    ODIVIDEODIVIDE 构建最小二乘问题
    ceresOCOLONOCOLONProblem problemOSEMICOLON
    for OPENBRACKETint i OASSIGN 0OSEMICOLON i OGREAT NOSEMICOLON iOPLUSOPLUSCLOSEBRACKET OPENCURLY
        problemODOTAddResidualBlockOPENBRACKET     ODIVIDEODIVIDE 向问题中添加误差项
            ODIVIDEODIVIDE 使用自动求导，模板参数：误差类型，输出维度，输入维度，维数要与前面struct中一致
            new ceresOCOLONOCOLONAutoDiffCostFunctionOGREATCURVEOUNDERSCOREFITTINGOUNDERSCORECOSTOCOMMA 1OCOMMA 3OLESSOPENBRACKET
                new CURVEOUNDERSCOREFITTINGOUNDERSCORECOSTOPENBRACKETxOUNDERSCOREdataOPENSQUAREiCLOSESQUAREOCOMMA yOUNDERSCOREdataOPENSQUAREiCLOSESQUARECLOSEBRACKET
            CLOSEBRACKETOCOMMA
            nullptrOCOMMA            ODIVIDEODIVIDE 核函数，这里不使用，为空
            abc                 ODIVIDEODIVIDE 待估计参数
        CLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 配置求解器
    ceresOCOLONOCOLONSolverOCOLONOCOLONOptions optionsOSEMICOLON     ODIVIDEODIVIDE 这里有很多配置项可以填
    optionsODOTlinearOUNDERSCOREsolverOUNDERSCOREtype OASSIGN ceresOCOLONOCOLONDENSEOUNDERSCORENORMALOUNDERSCORECHOLESKYOSEMICOLON  ODIVIDEODIVIDE 增量方程如何求解
    optionsODOTminimizerOUNDERSCOREprogressOUNDERSCOREtoOUNDERSCOREstdout OASSIGN trueOSEMICOLON   ODIVIDEODIVIDE 输出到cout
    
    ceresOCOLONOCOLONSolverOCOLONOCOLONSummary summaryOSEMICOLON                ODIVIDEODIVIDE 优化信息
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t1 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    ceresOCOLONOCOLONSolveOPENBRACKEToptionsOCOMMA OBANDproblemOCOMMA OBANDsummaryCLOSEBRACKETOSEMICOLON  ODIVIDEODIVIDE 开始优化
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t2 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    chronoOCOLONOCOLONdurationOGREATdoubleOLESS timeOUNDERSCOREused OASSIGN chronoOCOLONOCOLONdurationOUNDERSCOREcastOGREATchronoOCOLONOCOLONdurationOGREATdoubleOLESSOLESSOPENBRACKETt2 OMINUS t1CLOSEBRACKETOSEMICOLON
    cout OGREATOGREAT "solve time cost OASSIGN " OGREATOGREAT timeOUNDERSCOREusedODOTcountOPENBRACKETCLOSEBRACKET OGREATOGREAT " secondsODOT " OGREATOGREAT endlOSEMICOLON
    
    ODIVIDEODIVIDE 输出结果
    cout OGREATOGREAT summaryODOTBriefReportOPENBRACKETCLOSEBRACKET OGREATOGREAT endlOSEMICOLON
    cout OGREATOGREAT "estimated aOCOMMAbOCOMMAc OASSIGN "OSEMICOLON
    for OPENBRACKETauto aOCOLONabcCLOSEBRACKET cout OGREATOGREAT a OGREATOGREAT " "OSEMICOLON
    cout OGREATOGREAT endlOSEMICOLON
    
    return 0OSEMICOLON
CLOSECURLY
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

程序中需要说明的地方均已加注释。可以看到，我们利用OpenCV的噪声生成器生成了100个带高斯噪声的数据，随后利用Ceres进行拟合。这里演示的Ceres用法有如下几项：

OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 定义残差块的类。方法是书写一个类（或结构体），并在类中定义带模板参数的OPENBRACKETCLOSEBRACKET运算符，这样该类就成为了一个OBACKSLASHtextbfOPENCURLY拟函数CLOSECURLY（Functor）OBACKSLASHfootnoteOPENCURLYCOPLUSOPLUS术语，因为带有括号运算符的类在使用括号算符时，就仿佛是一个函数一样。CLOSECURLY。这种定义方式使得Ceres可以像调用函数一样，对该类的某个对象（比如a）调用aOGREATdoubleOLESSOPENBRACKETCLOSEBRACKET方法。事实上，Ceres会把雅可比矩阵作为类型参数传入此函数，从而实现自动求导的功能。
	OBACKSLASHitem 程序中的double abcOPENSQUARE3CLOSESQUARE即为参数块，而对于残差块，我们对每一个数据构造CURVEOBACKSLASHOUNDERSCOREFITTINGOBACKSLASHOUNDERSCORECOST对象，然后调用AddResidualBlock将误差项添加到目标函数中。由于优化需要梯度，我们有若干种选择：（1）使用Ceres的自动求导（Auto Diff）；（2）使用数值求导（Numeric Diff）OBACKSLASHfootnoteOPENCURLY自动求导也是用数值导数实现的，但由于是模板运算，所以运行更快一些。CLOSECURLY；（3）自行推导解析的导数形式，提供给Ceres。因为自动求导在编码上是最方便的，于是我们使用自动求导。
	OBACKSLASHitem 自动求导需要指定误差项和优化变量的维度。这里的误差是标量，维度为1；优化的是ODOLLARaOCOMMAbOCOMMAcODOLLAR三个量，维度为3。于是，在自动求导类AutoDiffCostFunction的模板参数中设定变量维度为1、3。
	OBACKSLASHitem 设定好问题后，调用Solve函数进行求解。你可以在options里配置（非常详细的）优化选项。例如，可以选择使用Line Search还是Trust Region、迭代次数、步长，等等。读者可以查看Options的定义，看看有哪些优化方法可选，当然默认的配置已经可用于很广泛的问题了。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY

最后，我们来看看实验结果。调用buildODIVIDEceresCurveFitting查看优化结果：
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLY
iter      cost      costOUNDERSCOREchange  OBBORgradientOBBOR   OBBORstepOBBOR    trOUNDERSCOREratio  trOUNDERSCOREradius  lsOUNDERSCOREiter  iterOUNDERSCOREtime  totalOUNDERSCOREtime
0  1ODOT597873eOPLUS06    0ODOT00eOPLUS00    3ODOT52eOPLUS06   0ODOT00eOPLUS00   0ODOT00eOPLUS00  1ODOT00eOPLUS04        0    2ODOT10eOMINUS05    7ODOT92eOMINUS05
1  1ODOT884440eOPLUS05    1ODOT41eOPLUS06    4ODOT86eOPLUS05   9ODOT88eOMINUS01   8ODOT82eOMINUS01  1ODOT81eOPLUS04        1    5ODOT60eOMINUS05    1ODOT05eOMINUS03
2  1ODOT784821eOPLUS04    1ODOT71eOPLUS05    6ODOT78eOPLUS04   9ODOT89eOMINUS01   9ODOT06eOMINUS01  3ODOT87eOPLUS04        1    2ODOT00eOMINUS05    1ODOT09eOMINUS03
3  1ODOT099631eOPLUS03    1ODOT67eOPLUS04    8ODOT58eOPLUS03   1ODOT10eOPLUS00   9ODOT41eOMINUS01  1ODOT16eOPLUS05        1    6ODOT70eOMINUS05    1ODOT16eOMINUS03
4  8ODOT784938eOPLUS01    1ODOT01eOPLUS03    6ODOT53eOPLUS02   1ODOT51eOPLUS00   9ODOT67eOMINUS01  3ODOT48eOPLUS05        1    1ODOT88eOMINUS05    1ODOT19eOMINUS03
5  5ODOT141230eOPLUS01    3ODOT64eOPLUS01    2ODOT72eOPLUS01   1ODOT13eOPLUS00   9ODOT90eOMINUS01  1ODOT05eOPLUS06        1    1ODOT81eOMINUS05    1ODOT22eOMINUS03
6  5ODOT096862eOPLUS01    4ODOT44eOMINUS01    4ODOT27eOMINUS01   1ODOT89eOMINUS01   9ODOT98eOMINUS01  3ODOT14eOPLUS06        1    1ODOT79eOMINUS05    1ODOT25eOMINUS03
7  5ODOT096851eOPLUS01    1ODOT10eOMINUS04    9ODOT53eOMINUS04   2ODOT84eOMINUS03   9ODOT99eOMINUS01  9ODOT41eOPLUS06        1    1ODOT81eOMINUS05    1ODOT28eOMINUS03
solve time cost OASSIGN 0ODOT00130755 secondsODOT 
Ceres Solver ReportOCOLON IterationsOCOLON 8OCOMMA Initial costOCOLON 1ODOT597873eOPLUS06OCOMMA Final costOCOLON 5ODOT096851eOPLUS01OCOMMA TerminationOCOLON CONVERGENCE
estimated aOCOMMAbOCOMMAc OASSIGN 0ODOT890908 2ODOT1719 0ODOT943628 
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

最终的优化值和我们上一节的实验结果基本相同，但运行速度上Ceres要相对慢一些。在我的机器上Ceres约使用了1ODOT3个毫秒，这比手写高斯牛顿法慢了约六倍左右。

希望读者通过这个简单的例子对Ceres的使用方法有一个大致了解。它的优点是提供了自动求导工具，使得不必去计算很麻烦的雅可比矩阵。Ceres的自动求导是通过模板元实现的，在编译时期就可以完成自动求导工作，不过仍然是数值导数。本书大部分时候仍然会介绍雅可比矩阵的计算，因为那样对理解问题更有帮助，而且在优化中更少出现问题。此外，Ceres的优化过程配置也很丰富，使其适合很广泛的最小二乘优化问题，包括SLAM之外的各种问题。

OBACKSLASHsubsectionOPENCURLY使用g2o进行曲线拟合CLOSECURLY
本讲的第2个实践部分将介绍另一个（主要在SLAM领域）广为使用的优化库：g2o（General Graphic Optimization，GODOLLAROHAT2ODOLLARO）。它是一个基于OBACKSLASHtextbfOPENCURLY图优化CLOSECURLY的库。图优化是一种将非线性优化与图论结合起来的理论，因此在使用它之前，我们花一点篇幅介绍一下图优化理论。

OBACKSLASHsubsubsectionOPENCURLY图优化理论简介CLOSECURLY
我们已经介绍了非线性最小二乘的求解方式。它们是由很多个误差项之和组成的。然而，仅有一组优化变量和许多个误差项，我们并不清楚它们之间的OBACKSLASHtextbfOPENCURLY关联CLOSECURLY。比如，某个优化变量ODOLLARxOUNDERSCOREjODOLLAR存在于多少个误差项中呢？我们能保证对它的优化是有意义的吗？进一步，我们希望能够直观地看到该优化问题OBACKSLASHtextbfOPENCURLY长什么样CLOSECURLY。于是，就牵涉到了图优化。

图优化，是把优化问题表现成OBACKSLASHtextbfOPENCURLY图（Graph）CLOSECURLY的一种方式。这里的OBACKSLASHtextbfOPENCURLY图CLOSECURLY是图论意义上的图。一个图由若干个OBACKSLASHtextbfOPENCURLY顶点（Vertex）CLOSECURLY，以及连接着这些顶点的OBACKSLASHtextbfOPENCURLY边（Edge）CLOSECURLY组成。进而，用OBACKSLASHtextbfOPENCURLY顶点CLOSECURLY表示OBACKSLASHtextbfOPENCURLY优化变量CLOSECURLY，用OBACKSLASHtextbfOPENCURLY边CLOSECURLY表示OBACKSLASHtextbfOPENCURLY误差项CLOSECURLY。于是，对任意一个上述形式的非线性最小二乘问题，我们可以构建与之对应的一个OBACKSLASHtextbfOPENCURLY图CLOSECURLY。我们可以简单地称它为OBACKSLASHtextbfOPENCURLY图CLOSECURLY，也可以用概率图里的定义，称之为OBACKSLASHtextbfOPENCURLY贝叶斯图CLOSECURLY或OBACKSLASHtextbfOPENCURLY因子图CLOSECURLY。

OBACKSLASHautorefOPENCURLYfigOCOLONgraphOMINUSoptimizationCLOSECURLYOTILDE是一个简单的图优化例子。我们用三角形表示相机位姿节点，用圆形表示路标点，它们构成了图优化的顶点；同时，实线表示相机的运动模型，虚线表示观测模型，它们构成了图优化的边。此时，虽然整个问题的数学形式仍是式OBACKSLASHeqrefOPENCURLYeqOCOLONleastOMINUSsquareCLOSECURLY那样，但现在我们可以直观地看到问题的OBACKSLASHtextbfOPENCURLY结构CLOSECURLY了。如果希望，也可以做OBACKSLASHtextbfOPENCURLY去掉孤立顶点CLOSECURLY或OBACKSLASHtextbfOPENCURLY优先优化边数较多（或按图论的术语，度数较大）的顶点CLOSECURLY这样的改进。但是最基本的图优化是用图模型来表达一个非线性最小二乘的优化问题。而我们可以利用图模型的某些性质做更好的优化。

OBACKSLASHbeginOPENCURLYfigureCLOSECURLYOPENSQUAREONOThtCLOSESQUARE
	OBACKSLASHcentering
	OBACKSLASHincludegraphicsOPENSQUAREwidthOASSIGN1ODOT0OBACKSLASHtextwidthCLOSESQUAREOPENCURLYOptimizationODIVIDEgraphOptimizationODOTpdfCLOSECURLY
	OBACKSLASHcaptionOPENCURLY图优化的例子。CLOSECURLY
	OBACKSLASHlabelOPENCURLYfigOCOLONgraphOMINUSoptimizationCLOSECURLY
OBACKSLASHendOPENCURLYfigureCLOSECURLY

g2o是一个通用的图优化库。“通用”意味着你可以在g2o里求解任何能够表示为图优化的最小二乘问题，显然包括上面谈的曲线拟合问题。下面我们来演示这个过程。

OBACKSLASHsubsectionOPENCURLYg2o的编译与安装CLOSECURLY
在使用一个库之前，我们需要对它进行编译和安装。读者应该已经体验过很多次这种过程了，它们基本大同小异。关于g2o，读者可以从GitHub下载它：OBACKSLASHurlOPENCURLYhttpsOCOLONODIVIDEODIVIDEgithubODOTcomODIVIDERainerKuemmerleODIVIDEg2oCLOSECURLY，或从本书提供的第三方代码库中获得。由于g2o还在继续更新，所以我建议你使用3rdparty下的g2o以保证版本与我的相同。

g2o也是一个cmake工程。我们先来安装它的依赖项（部分依赖项与Ceres重合）：
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNshOCOMMAcaptionOASSIGN终端输入：CLOSESQUARE
sudo aptOMINUSget install qt5OMINUSqmake qt5OMINUSdefault libqglviewerOMINUSdevOMINUSqt5 libsuitesparseOMINUSdev libcxsparse3 libcholmod3
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

然后，按照cmake的方式对g2o进行编译安装即可，这里略去对该过程的说明。安装完成后，g2o的头文件将位于ODIVIDEusrODIVIDElocalODIVIDEg2o下，库文件位于ODIVIDEusrODIVIDElocalODIVIDElibODIVIDE下。现在，我们重新考虑Ceres例程中的曲线拟合实验，在g2o中实验一遍。

OBACKSLASHsubsectionOPENCURLY使用g2o拟合曲线CLOSECURLY
为了使用g2o，首先要将曲线拟合问题抽象成图优化。这个过程中，只要记住OBACKSLASHtextbfOPENCURLY节点为优化变量，边为误差项CLOSECURLY即可。曲线拟合的图优化问题可以画成OBACKSLASHautorefOPENCURLYfigOCOLONgraphOMINUSfittingCLOSECURLYOTILDE的形式。

OBACKSLASHbeginOPENCURLYfigureCLOSECURLYOPENSQUAREONOThtCLOSESQUARE
	OBACKSLASHcentering
	OBACKSLASHincludegraphicsOPENSQUAREwidthOASSIGNODOT9OBACKSLASHtextwidthCLOSESQUAREOPENCURLYOptimizationODIVIDEgraphFittingODOTpdfCLOSECURLY
	OBACKSLASHcaptionOPENCURLY曲线拟合对应的图优化模型。（莫明其妙地有些像华为的标志）CLOSECURLY
	OBACKSLASHlabelOPENCURLYfigOCOLONgraphOMINUSfittingCLOSECURLY
OBACKSLASHendOPENCURLYfigureCLOSECURLY

在曲线拟合问题中，整个问题只有一个顶点：曲线模型的参数ODOLLARaOCOMMAbOCOMMAcODOLLAR；而各个带噪声的数据点，构成了一个个误差项，也就是图优化的边。但这里的边与我们平时想的边不太一样，它们是OBACKSLASHtextbfOPENCURLY一元边CLOSECURLY（Unary Edge），即OBACKSLASHtextbfOPENCURLY只连接一个顶点CLOSECURLY——因为整个图只有一个顶点。所以在OBACKSLASHautorefOPENCURLYfigOCOLONgraphOMINUSfittingCLOSECURLYOTILDE中，我们只能把它画成自己连到自己的样子。事实上，图优化中一条边可以连接一个、两个或多个顶点，这主要反映每个误差与多少个优化变量有关。在稍有些玄妙的说法中，我们把它叫作OBACKSLASHtextbfOPENCURLY超边CLOSECURLY（Hyper Edge），整个图叫作OBACKSLASHtextbfOPENCURLY超图CLOSECURLY（Hyper Graph）OBACKSLASHfootnoteOPENCURLY显然我个人并不太喜欢有些故弄玄虚的说法，我是个自然主义者。CLOSECURLY。

弄清了这个图模型之后，接下来就是在g2o中建立该模型进行优化了。作为g2o的用户，我们要做的事主要包含以下步骤：

OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 定义顶点和边的类型。
	OBACKSLASHitem 构建图。
	OBACKSLASHitem 选择优化算法。
	OBACKSLASHitem 调用g2o进行优化，返回结果。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY

这部分和Ceres是非常相似的，当然程序在书写上会有一些不同。下面演示一下程序。

OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNcOPLUSOPLUSOCOMMAcaptionOASSIGNslambookODIVIDEch6ODIVIDEg2oCurveFittingODOTcppCLOSESQUARE
OSINGLEHASHinclude OGREATiostreamOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEg2oOUNDERSCOREcoreOUNDERSCOREapiODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEbaseOUNDERSCOREvertexODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEbaseOUNDERSCOREunaryOUNDERSCOREedgeODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEblockOUNDERSCOREsolverODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEoptimizationOUNDERSCOREalgorithmOUNDERSCORElevenbergODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEoptimizationOUNDERSCOREalgorithmOUNDERSCOREgaussOUNDERSCOREnewtonODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEcoreODIVIDEoptimizationOUNDERSCOREalgorithmOUNDERSCOREdoglegODOThOLESS
OSINGLEHASHinclude OGREATg2oODIVIDEsolversODIVIDEdenseODIVIDElinearOUNDERSCOREsolverOUNDERSCOREdenseODOThOLESS
OSINGLEHASHinclude OGREATEigenODIVIDECoreOLESS
OSINGLEHASHinclude OGREATopencv2ODIVIDEcoreODIVIDEcoreODOThppOLESS
OSINGLEHASHinclude OGREATcmathOLESS
OSINGLEHASHinclude OGREATchronoOLESS

using namespace stdOSEMICOLON

ODIVIDEODIVIDE 曲线模型的顶点，模板参数：优化变量维度和数据类型
class CurveFittingVertex OCOLON public g2oOCOLONOCOLONBaseVertexOGREAT3OCOMMA EigenOCOLONOCOLONVector3dOLESS OPENCURLY
publicOCOLON
    EIGENOUNDERSCOREMAKEOUNDERSCOREALIGNEDOUNDERSCOREOPERATOROUNDERSCORENEW
    
    ODIVIDEODIVIDE 重置
    virtual void setToOriginImplOPENBRACKETCLOSEBRACKET override OPENCURLY
        OUNDERSCOREestimate OGREATOGREAT 0OCOMMA 0OCOMMA 0OSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 更新
    virtual void oplusImplOPENBRACKETconst double OMULTIPLYupdateCLOSEBRACKET override OPENCURLY
        OUNDERSCOREestimate OPLUSOASSIGN EigenOCOLONOCOLONVector3dOPENBRACKETupdateCLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 存盘和读盘：留空
    virtual bool readOPENBRACKETistream OBANDinCLOSEBRACKET OPENCURLYCLOSECURLY
    virtual bool writeOPENBRACKETostream OBANDoutCLOSEBRACKET const OPENCURLYCLOSECURLY
CLOSECURLYOSEMICOLON

ODIVIDEODIVIDE 误差模型 模板参数：观测值维度，类型，连接顶点类型
class CurveFittingEdge OCOLON public g2oOCOLONOCOLONBaseUnaryEdgeOGREAT1OCOMMA doubleOCOMMA CurveFittingVertexOLESS OPENCURLY
publicOCOLON
    EIGENOUNDERSCOREMAKEOUNDERSCOREALIGNEDOUNDERSCOREOPERATOROUNDERSCORENEW
    
    CurveFittingEdgeOPENBRACKETdouble xCLOSEBRACKET OCOLON BaseUnaryEdgeOPENBRACKETCLOSEBRACKETOCOMMA OUNDERSCORExOPENBRACKETxCLOSEBRACKET OPENCURLYCLOSECURLY
    
    ODIVIDEODIVIDE 计算曲线模型误差
    virtual void computeErrorOPENBRACKETCLOSEBRACKET override OPENCURLY
        const CurveFittingVertex OMULTIPLYv OASSIGN staticOUNDERSCOREcastOGREATconst CurveFittingVertex OMULTIPLYOLESS OPENBRACKETOUNDERSCOREverticesOPENSQUARE0CLOSESQUARECLOSEBRACKETOSEMICOLON
        const EigenOCOLONOCOLONVector3d abc OASSIGN vOMINUSOLESSestimateOPENBRACKETCLOSEBRACKETOSEMICOLON
        OUNDERSCOREerrorOPENBRACKET0OCOMMA 0CLOSEBRACKET OASSIGN OUNDERSCOREmeasurement OMINUS stdOCOLONOCOLONexpOPENBRACKETabcOPENBRACKET0OCOMMA 0CLOSEBRACKET OMULTIPLY OUNDERSCOREx OMULTIPLY OUNDERSCOREx OPLUS abcOPENBRACKET1OCOMMA 0CLOSEBRACKET OMULTIPLY OUNDERSCOREx OPLUS abcOPENBRACKET2OCOMMA 0CLOSEBRACKETCLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 计算雅可比矩阵
    virtual void linearizeOplusOPENBRACKETCLOSEBRACKET override OPENCURLY
        const CurveFittingVertex OMULTIPLYv OASSIGN staticOUNDERSCOREcastOGREATconst CurveFittingVertex OMULTIPLYOLESS OPENBRACKETOUNDERSCOREverticesOPENSQUARE0CLOSESQUARECLOSEBRACKETOSEMICOLON
        const EigenOCOLONOCOLONVector3d abc OASSIGN vOMINUSOLESSestimateOPENBRACKETCLOSEBRACKETOSEMICOLON
        double y OASSIGN expOPENBRACKETabcOPENSQUARE0CLOSESQUARE OMULTIPLY OUNDERSCOREx OMULTIPLY OUNDERSCOREx OPLUS abcOPENSQUARE1CLOSESQUARE OMULTIPLY OUNDERSCOREx OPLUS abcOPENSQUARE2CLOSESQUARECLOSEBRACKETOSEMICOLON
        OUNDERSCOREjacobianOplusXiOPENSQUARE0CLOSESQUARE OASSIGN OMINUSOUNDERSCOREx OMULTIPLY OUNDERSCOREx OMULTIPLY yOSEMICOLON
        OUNDERSCOREjacobianOplusXiOPENSQUARE1CLOSESQUARE OASSIGN OMINUSOUNDERSCOREx OMULTIPLY yOSEMICOLON
        OUNDERSCOREjacobianOplusXiOPENSQUARE2CLOSESQUARE OASSIGN OMINUSyOSEMICOLON
    CLOSECURLY
    
    virtual bool readOPENBRACKETistream OBANDinCLOSEBRACKET OPENCURLYCLOSECURLY
    virtual bool writeOPENBRACKETostream OBANDoutCLOSEBRACKET const OPENCURLYCLOSECURLY
publicOCOLON
    double OUNDERSCORExOSEMICOLON  ODIVIDEODIVIDE x 值， y 值为 OUNDERSCOREmeasurement
CLOSECURLYOSEMICOLON

int mainOPENBRACKETint argcOCOMMA char OMULTIPLYOMULTIPLYargvCLOSEBRACKET OPENCURLY
    ODIVIDEODIVIDE 省略数据生成部分代码
    ODIVIDEODIVIDE 构建图优化，先设定g2o
    typedef g2oOCOLONOCOLONBlockSolverOGREATg2oOCOLONOCOLONBlockSolverTraitsOGREAT3OCOMMA 1OLESSOLESS BlockSolverTypeOSEMICOLON  ODIVIDEODIVIDE 每个误差项优化变量维度为3，误差值维度为1
    typedef g2oOCOLONOCOLONLinearSolverDenseOGREATBlockSolverTypeOCOLONOCOLONPoseMatrixTypeOLESS LinearSolverTypeOSEMICOLON ODIVIDEODIVIDE 线性求解器类型
    
    ODIVIDEODIVIDE 梯度下降方法，可以从GNOCOMMA LMOCOMMA DogLeg 中选
    auto solver OASSIGN new g2oOCOLONOCOLONOptimizationAlgorithmGaussNewtonOPENBRACKET
        g2oOCOLONOCOLONmakeOUNDERSCOREuniqueOGREATBlockSolverTypeOLESSOPENBRACKETg2oOCOLONOCOLONmakeOUNDERSCOREuniqueOGREATLinearSolverTypeOLESSOPENBRACKETCLOSEBRACKETCLOSEBRACKETCLOSEBRACKETOSEMICOLON
    g2oOCOLONOCOLONSparseOptimizer optimizerOSEMICOLON     ODIVIDEODIVIDE 图模型
    optimizerODOTsetAlgorithmOPENBRACKETsolverCLOSEBRACKETOSEMICOLON   ODIVIDEODIVIDE 设置求解器
    optimizerODOTsetVerboseOPENBRACKETtrueCLOSEBRACKETOSEMICOLON       ODIVIDEODIVIDE 打开调试输出
    
    ODIVIDEODIVIDE 往图中增加顶点
    CurveFittingVertex OMULTIPLYv OASSIGN new CurveFittingVertexOPENBRACKETCLOSEBRACKETOSEMICOLON
    vOMINUSOLESSsetEstimateOPENBRACKETEigenOCOLONOCOLONVector3dOPENBRACKETaeOCOMMA beOCOMMA ceCLOSEBRACKETCLOSEBRACKETOSEMICOLON
    vOMINUSOLESSsetIdOPENBRACKET0CLOSEBRACKETOSEMICOLON
    optimizerODOTaddVertexOPENBRACKETvCLOSEBRACKETOSEMICOLON
    
    ODIVIDEODIVIDE 往图中增加边
    for OPENBRACKETint i OASSIGN 0OSEMICOLON i OGREAT NOSEMICOLON iOPLUSOPLUSCLOSEBRACKET OPENCURLY
        CurveFittingEdge OMULTIPLYedge OASSIGN new CurveFittingEdgeOPENBRACKETxOUNDERSCOREdataOPENSQUAREiCLOSESQUARECLOSEBRACKETOSEMICOLON
        edgeOMINUSOLESSsetIdOPENBRACKETiCLOSEBRACKETOSEMICOLON
        edgeOMINUSOLESSsetVertexOPENBRACKET0OCOMMA vCLOSEBRACKETOSEMICOLON                ODIVIDEODIVIDE 设置连接的顶点
        edgeOMINUSOLESSsetMeasurementOPENBRACKETyOUNDERSCOREdataOPENSQUAREiCLOSESQUARECLOSEBRACKETOSEMICOLON      ODIVIDEODIVIDE 观测数值
        edgeOMINUSOLESSsetInformationOPENBRACKETEigenOCOLONOCOLONMatrixOGREATdoubleOCOMMA 1OCOMMA 1OLESSOCOLONOCOLONIdentityOPENBRACKETCLOSEBRACKET OMULTIPLY 1 ODIVIDE OPENBRACKETwOUNDERSCOREsigma OMULTIPLY wOUNDERSCOREsigmaCLOSEBRACKETCLOSEBRACKETOSEMICOLON ODIVIDEODIVIDE 信息矩阵：协方差矩阵之逆
        optimizerODOTaddEdgeOPENBRACKETedgeCLOSEBRACKETOSEMICOLON
    CLOSECURLY
    
    ODIVIDEODIVIDE 执行优化
    cout OGREATOGREAT "start optimization" OGREATOGREAT endlOSEMICOLON
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t1 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    optimizerODOTinitializeOptimizationOPENBRACKETCLOSEBRACKETOSEMICOLON
    optimizerODOToptimizeOPENBRACKET10CLOSEBRACKETOSEMICOLON
    chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONtimeOUNDERSCOREpoint t2 OASSIGN chronoOCOLONOCOLONsteadyOUNDERSCOREclockOCOLONOCOLONnowOPENBRACKETCLOSEBRACKETOSEMICOLON
    chronoOCOLONOCOLONdurationOGREATdoubleOLESS timeOUNDERSCOREused OASSIGN chronoOCOLONOCOLONdurationOUNDERSCOREcastOGREATchronoOCOLONOCOLONdurationOGREATdoubleOLESSOLESSOPENBRACKETt2 OMINUS t1CLOSEBRACKETOSEMICOLON
    cout OGREATOGREAT "solve time cost OASSIGN " OGREATOGREAT timeOUNDERSCOREusedODOTcountOPENBRACKETCLOSEBRACKET OGREATOGREAT " secondsODOT " OGREATOGREAT endlOSEMICOLON
    
    ODIVIDEODIVIDE 输出优化值
    EigenOCOLONOCOLONVector3d abcOUNDERSCOREestimate OASSIGN vOMINUSOLESSestimateOPENBRACKETCLOSEBRACKETOSEMICOLON
    cout OGREATOGREAT "estimated modelOCOLON " OGREATOGREAT abcOUNDERSCOREestimateODOTtransposeOPENBRACKETCLOSEBRACKET OGREATOGREAT endlOSEMICOLON
    
    return 0OSEMICOLON
CLOSECURLY
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

在这个程序中，我们从g2o派生出了用于曲线拟合的图优化顶点和边：CurveFittingVertex和CurveFittingEdge，这实质上扩展了g2o的使用方式。这两个类分别派生自BaseVertex和BaseUnaryEdge类。在派生类中，我们重写了重要的虚函数：

OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 顶点的更新函数：oplusImpl。我们知道优化过程最重要的是增量ODOLLAROBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的计算，而该函数处理的是ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREOPENCURLYkOPLUS1CLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYxCLOSECURLYOUNDERSCOREk OPLUS OBACKSLASHDelta OBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR的过程。
	
	读者也许觉得这并不是什么值得一提的事情，因为仅仅是个简单的加法而已，为什么g2o不帮我们完成呢？在曲线拟合过程中，由于优化变量（曲线参数）本身位于OBACKSLASHtextbfOPENCURLY向量空间CLOSECURLY中，这个更新计算确实就是简单的加法。但是，当优化变量不在向量空间中时，比如说ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLYODOLLAR是相机位姿，它本身不一定有加法运算。这时，就需要重新定义OBACKSLASHtextbfOPENCURLY增量如何加到现有的估计上CLOSECURLY的行为了。按照第4讲的解释，我们可能使用左乘更新或右乘更新，而不是直接的加法。
	
	OBACKSLASHitem 顶点的重置函数：setToOriginImpl。这是平凡的，我们把估计值置零即可。
	
	OBACKSLASHitem 边的误差计算函数：computeError。该函数需要取出边所连接的顶点的当前估计值，根据曲线模型，与它的观测值进行比较。这和最小二乘问题中的误差模型是一致的。
    
    OBACKSLASHitem 边的雅可比计算函数：linearizeOplus。这个函数里我们计算了每条边相对于顶点的雅可比。
	
	OBACKSLASHitem 存盘和读盘函数：read、write。由于我们并不想进行读ODIVIDE写操作，所以留空。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY

定义了顶点和边之后，我们在main函数里声明了一个图模型，然后按照生成的噪声数据，往图模型中添加顶点和边，最后调用优化函数进行优化。g2o会给出优化的结果：

OBACKSLASHclearpage
OBACKSLASHbeginOPENCURLYlstlistingCLOSECURLYOPENSQUARElanguageOASSIGNshOCOMMAcaptionOASSIGN终端输出：CLOSESQUARE
start optimization
iterationOASSIGN 0	 chi2OASSIGN 376785ODOT128234	 timeOASSIGN 3ODOT3299eOMINUS05	 cumTimeOASSIGN 3ODOT3299eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 1	 chi2OASSIGN 35673ODOT566018	 timeOASSIGN 1ODOT3789eOMINUS05	 cumTimeOASSIGN 4ODOT7088eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 2	 chi2OASSIGN 2195ODOT012304	 timeOASSIGN 1ODOT2323eOMINUS05	 cumTimeOASSIGN 5ODOT9411eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 3	 chi2OASSIGN 174ODOT853126	 timeOASSIGN 1ODOT3302eOMINUS05	 cumTimeOASSIGN 7ODOT2713eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 4	 chi2OASSIGN 102ODOT779695	 timeOASSIGN 1ODOT2424eOMINUS05	 cumTimeOASSIGN 8ODOT5137eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 5	 chi2OASSIGN 101ODOT937194	 timeOASSIGN 1ODOT2523eOMINUS05	 cumTimeOASSIGN 9ODOT766eOMINUS05	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 6	 chi2OASSIGN 101ODOT937020	 timeOASSIGN 1ODOT2268eOMINUS05	 cumTimeOASSIGN 0ODOT000109928	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 7	 chi2OASSIGN 101ODOT937020	 timeOASSIGN 1ODOT2612eOMINUS05	 cumTimeOASSIGN 0ODOT00012254	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 8	 chi2OASSIGN 101ODOT937020	 timeOASSIGN 1ODOT2159eOMINUS05	 cumTimeOASSIGN 0ODOT000134699	 edgesOASSIGN 100	 schurOASSIGN 0
iterationOASSIGN 9	 chi2OASSIGN 101ODOT937020	 timeOASSIGN 1ODOT2688eOMINUS05	 cumTimeOASSIGN 0ODOT000147387	 edgesOASSIGN 100	 schurOASSIGN 0
solve time cost OASSIGN 0ODOT000919301 secondsODOT 
estimated modelOCOLON 0ODOT890912   2ODOT1719 0ODOT943629
OBACKSLASHendOPENCURLYlstlistingCLOSECURLY

我们使用高斯—牛顿方法进行梯度下降，在迭代了9次后得到优化结果，与Ceres和手写高斯牛顿法相差无几。从运行速度来看，我们实验结论是手写快于g2o，而g2o快于Ceres。这是一个大体符合直觉的经验，通用性和高效性往往是互相矛盾的。但是本实验中Ceres使用了自动求导，且求解器配置与高斯牛顿还不完全一致，所以看起来慢一些。

OBACKSLASHsectionOPENCURLY小结CLOSECURLY
本节介绍了SLAM中经常碰到的一种非线性优化问题：由许多个误差项平方和组成的最小二乘问题。我们介绍了它的定义和求解，并且讨论了两种主要的梯度下降方式：高斯牛顿法和列文伯格—马夸尔特方法。在实践部分中，分别使用了手写高斯牛顿法、Ceres和g2o两种优化库求解同一个曲线拟合问题，发现它们给出了相似的结果。

由于还没有详细谈Bundle Adjustment，所以我们在实践部分选择了曲线拟合这样一个简单但有代表性的例子，以演示一般的非线性最小二乘求解方式。特别地，如果用g2o来拟合曲线，必须先把问题转换为图优化，定义新的顶点和边，这种做法是有一些迂回的——g2o的主要目的并不在此。相比之下，Ceres定义误差项求曲线拟合问题则自然了很多，因为它本身即是一个优化库。然而，在SLAM中更多的问题是，一个带有许多个相机位姿和许多个空间点的优化问题如何求解。特别地，当相机位姿以李代数表示时，误差项关于相机位姿的导数如何计算，将是一件值得详细讨论的事。我们将在后续内容发现，g2o提供了大量现成的顶点和边，非常便于相机位姿估计问题。而在Ceres中，我们不得不自己实现每一个Cost Function，有一些不便。

在实践部分的两个程序中，我们没有去计算曲线模型关于三个参数的导数，而是利用了优化库的数值求导，这使得理论和代码都会简洁一些。Ceres库提供了基于模板元的自动求导和运行时的数值求导，而g2o只提供了运行时数值求导这一种方式。但是，对于大多数问题，如果能够推导出雅可比矩阵的解析形式并告诉优化库，就可以避免数值求导中的诸多问题。

最后，希望读者能够适应Ceres和g2o这些大量使用模板编程的方式。也许一开始会看上去比较吓人（特别是Ceres设置残差块的括号运算符，以及g2o初始化部分的代码），但是熟悉之后，就会觉得这样的方式是自然的，而且容易扩展。我们将在SLAM后端一讲中继续讨论稀疏性、核函数、位姿图（Pose Graph）等问题。

OBACKSLASHsectionOMULTIPLYOPENCURLY习题CLOSECURLY
OBACKSLASHbeginOPENCURLYenumerateCLOSECURLY
	OBACKSLASHitem 证明线性方程ODOLLAROBACKSLASHbmOPENCURLYACLOSECURLY OBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OBACKSLASHbmOPENCURLYbCLOSECURLYODOLLAR当系数矩阵ODOLLAROBACKSLASHbmOPENCURLYACLOSECURLYODOLLAR超定时，最小二乘解为ODOLLAROBACKSLASHbmOPENCURLYxCLOSECURLY OASSIGN OPENBRACKETOBACKSLASHbmOPENCURLYACLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLYOBACKSLASHbmOPENCURLYACLOSECURLYCLOSEBRACKETOHATOPENCURLYOMINUS1CLOSECURLYOBACKSLASHbmOPENCURLYACLOSECURLYOHATOBACKSLASHmathrmOPENCURLYTCLOSECURLY OBACKSLASHbmOPENCURLYbCLOSECURLYODOLLAR。
	OBACKSLASHitem 调研最速下降法、牛顿法、高斯牛顿法和列文伯格—马夸尔特方法各有什么优缺点。除了我们举的Ceres库和g2o库，还有哪些常用的优化库？（你可能会找到一些MATLAB上的库。）
	OBACKSLASHitem 为什么高斯牛顿法的增量方程系数矩阵可能不正定？不正定有什么几何含义？为什么在这种情况下解就不稳定了？
	OBACKSLASHitem DogLeg是什么？它与高斯牛顿法和列文伯格—马夸尔特方法有何异同？请搜索相关的材料OBACKSLASHfootnoteOPENCURLYOBACKSLASHmboxOPENCURLY例如，CLOSECURLYOBACKSLASHurlOPENCURLYhttpOCOLONODIVIDEODIVIDEwwwODOTnumericalODOTrlODOTacODOTukODIVIDEpeopleODIVIDEnimgODIVIDEcourseODIVIDElecturesODIVIDEraphaelODIVIDElecturesODIVIDElec7slidesODOTpdfCLOSECURLY。CLOSECURLY。
	OBACKSLASHitem 阅读Ceres的教学材料（OBACKSLASHurlOPENCURLYhttpOCOLONODIVIDEODIVIDEceresOMINUSsolverODOTorgODIVIDEtutorialODOThtmlCLOSECURLY）以更好地掌握其用法。
	OBACKSLASHitem 阅读g2o自带的文档，你能看懂它吗？如果还不能完全看懂，请在第10讲和第11讲之后回来再看。
	OBACKSLASHitemOPENSQUAREOBACKSLASHoptionalCLOSESQUARE 请更改曲线拟合实验中的曲线模型，并用Ceres和g2o进行优化实验。例如，可以使用更多的参数和更复杂的模型。
OBACKSLASHendOPENCURLYenumerateCLOSECURLY
